{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57308c9a-552b-42e5-b4e4-c911c81f5204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.3.189)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.15.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.1.1)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: polars in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.32.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etuptools (c:\\users\\adars\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0ebff5-072d-4bfa-a00e-e0762a964ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING VIDEO PERSON COUNTER\n",
      "==================================================\n",
      "üöÄ Initializing Video Person Counter...\n",
      "üì• Trying to load yolo11n.pt...\n",
      "‚úÖ Successfully loaded yolo11n.pt\n",
      "\n",
      "‚úÖ INITIALIZATION SUCCESSFUL!\n",
      "üì± Model: yolo11n.pt\n",
      "\n",
      "üéØ READY TO PLAY VIDEO WITH PEOPLE COUNTING!\n",
      "\n",
      "üé¨ CONTROLS:\n",
      "   'q' or ESC = Quit\n",
      "   SPACE = Pause/Resume\n",
      "   's' = Save screenshot\n",
      "üé• Opening video: testing8.mp4\n",
      "üìπ Video Info: 1920x1080, 30 FPS, 407 frames, 13.6s\n",
      "üé¨ Starting playback with people counting...\n",
      "Press 'q' to quit, SPACE to pause/resume\n",
      "Frame 1: 13 people detected\n",
      "Frame 2: 12 people detected\n",
      "Frame 3: 14 people detected\n",
      "Frame 4: 14 people detected\n",
      "Frame 5: 13 people detected\n",
      "Frame 6: 15 people detected\n",
      "Frame 7: 16 people detected\n",
      "Frame 8: 13 people detected\n",
      "Frame 9: 12 people detected\n",
      "Frame 10: 9 people detected\n",
      "Frame 11: 12 people detected\n",
      "Frame 12: 11 people detected\n",
      "Frame 13: 9 people detected\n",
      "Frame 14: 9 people detected\n",
      "Frame 15: 10 people detected\n",
      "Frame 16: 10 people detected\n",
      "Frame 17: 12 people detected\n",
      "Frame 18: 12 people detected\n",
      "Frame 19: 12 people detected\n",
      "Frame 20: 10 people detected\n",
      "Frame 21: 11 people detected\n",
      "Frame 22: 7 people detected\n",
      "Frame 23: 12 people detected\n",
      "Frame 24: 14 people detected\n",
      "Frame 25: 16 people detected\n",
      "Frame 26: 15 people detected\n",
      "Frame 27: 15 people detected\n",
      "Frame 28: 12 people detected\n",
      "Frame 29: 10 people detected\n",
      "Frame 30: 12 people detected\n",
      "Frame 31: 12 people detected\n",
      "Frame 32: 12 people detected\n",
      "Frame 33: 16 people detected\n",
      "Frame 34: 14 people detected\n",
      "Frame 35: 14 people detected\n",
      "Frame 36: 15 people detected\n",
      "Frame 37: 13 people detected\n",
      "Frame 38: 14 people detected\n",
      "Frame 39: 14 people detected\n",
      "Frame 40: 15 people detected\n",
      "Frame 41: 13 people detected\n",
      "Frame 42: 12 people detected\n",
      "Frame 43: 14 people detected\n",
      "Frame 44: 16 people detected\n",
      "Frame 45: 13 people detected\n",
      "Frame 46: 15 people detected\n",
      "Frame 47: 13 people detected\n",
      "Frame 48: 12 people detected\n",
      "Frame 49: 12 people detected\n",
      "Frame 50: 12 people detected\n",
      "Frame 51: 11 people detected\n",
      "Frame 52: 9 people detected\n",
      "Frame 53: 9 people detected\n",
      "Frame 54: 14 people detected\n",
      "Frame 55: 12 people detected\n",
      "Frame 56: 11 people detected\n",
      "Frame 57: 15 people detected\n",
      "Frame 58: 14 people detected\n",
      "Frame 59: 13 people detected\n",
      "Frame 60: 15 people detected\n",
      "Frame 61: 17 people detected\n",
      "Frame 62: 17 people detected\n",
      "Frame 63: 20 people detected\n",
      "Frame 64: 18 people detected\n",
      "Frame 65: 15 people detected\n",
      "Frame 66: 13 people detected\n",
      "Frame 67: 11 people detected\n",
      "Frame 68: 10 people detected\n",
      "Frame 69: 14 people detected\n",
      "Frame 70: 17 people detected\n",
      "Frame 71: 15 people detected\n",
      "Frame 72: 8 people detected\n",
      "Frame 73: 14 people detected\n",
      "Frame 74: 9 people detected\n",
      "Frame 75: 13 people detected\n",
      "Frame 76: 15 people detected\n",
      "Frame 77: 15 people detected\n",
      "Frame 78: 13 people detected\n",
      "Frame 79: 19 people detected\n",
      "Frame 80: 19 people detected\n",
      "Frame 81: 11 people detected\n",
      "Frame 82: 15 people detected\n",
      "Frame 83: 12 people detected\n",
      "Frame 84: 9 people detected\n",
      "Frame 85: 5 people detected\n",
      "Frame 86: 6 people detected\n",
      "Frame 87: 13 people detected\n",
      "Frame 88: 15 people detected\n",
      "Frame 89: 20 people detected\n",
      "Frame 90: 22 people detected\n",
      "Frame 91: 17 people detected\n",
      "Frame 92: 13 people detected\n",
      "Frame 93: 17 people detected\n",
      "Frame 94: 17 people detected\n",
      "Frame 95: 12 people detected\n",
      "Frame 96: 9 people detected\n",
      "Frame 97: 14 people detected\n",
      "Frame 98: 7 people detected\n",
      "Frame 99: 15 people detected\n",
      "Frame 100: 14 people detected\n",
      "Frame 101: 13 people detected\n",
      "Frame 102: 15 people detected\n",
      "Frame 103: 10 people detected\n",
      "Frame 104: 7 people detected\n",
      "Frame 105: 16 people detected\n",
      "Frame 106: 11 people detected\n",
      "Frame 107: 8 people detected\n",
      "Frame 108: 11 people detected\n",
      "Frame 109: 8 people detected\n",
      "Frame 110: 15 people detected\n",
      "Frame 111: 14 people detected\n",
      "Frame 112: 17 people detected\n",
      "Frame 113: 15 people detected\n",
      "Frame 114: 18 people detected\n",
      "Frame 115: 11 people detected\n",
      "Frame 116: 10 people detected\n",
      "Frame 117: 7 people detected\n",
      "Frame 118: 14 people detected\n",
      "Frame 119: 15 people detected\n",
      "Frame 120: 15 people detected\n",
      "Frame 121: 15 people detected\n",
      "Frame 122: 11 people detected\n",
      "Frame 123: 13 people detected\n",
      "Frame 124: 17 people detected\n",
      "Frame 125: 17 people detected\n",
      "Frame 126: 13 people detected\n",
      "Frame 127: 14 people detected\n",
      "Frame 128: 14 people detected\n",
      "Frame 129: 17 people detected\n",
      "Frame 130: 17 people detected\n",
      "Frame 131: 15 people detected\n",
      "Frame 132: 14 people detected\n",
      "Frame 133: 20 people detected\n",
      "Frame 134: 13 people detected\n",
      "Frame 135: 17 people detected\n",
      "Frame 136: 13 people detected\n",
      "Frame 137: 16 people detected\n",
      "Frame 138: 17 people detected\n",
      "Frame 139: 16 people detected\n",
      "Frame 140: 15 people detected\n",
      "Frame 141: 9 people detected\n",
      "Frame 142: 18 people detected\n",
      "Frame 143: 19 people detected\n",
      "Frame 144: 17 people detected\n",
      "Frame 145: 15 people detected\n",
      "Frame 146: 8 people detected\n",
      "Frame 147: 14 people detected\n",
      "Frame 148: 17 people detected\n",
      "Frame 149: 13 people detected\n",
      "Frame 150: 13 people detected\n",
      "Frame 151: 16 people detected\n",
      "Frame 152: 14 people detected\n",
      "Frame 153: 18 people detected\n",
      "Frame 154: 15 people detected\n",
      "Frame 155: 14 people detected\n",
      "Frame 156: 13 people detected\n",
      "Frame 157: 9 people detected\n",
      "Frame 158: 14 people detected\n",
      "Frame 159: 12 people detected\n",
      "Frame 160: 9 people detected\n",
      "Frame 161: 11 people detected\n",
      "Frame 162: 14 people detected\n",
      "Frame 163: 15 people detected\n",
      "Frame 164: 16 people detected\n",
      "Frame 165: 15 people detected\n",
      "Frame 166: 14 people detected\n",
      "Frame 167: 11 people detected\n",
      "Frame 168: 12 people detected\n",
      "Frame 169: 15 people detected\n",
      "Frame 170: 12 people detected\n",
      "Frame 171: 9 people detected\n",
      "Frame 172: 9 people detected\n",
      "Frame 173: 16 people detected\n",
      "Frame 174: 15 people detected\n",
      "Frame 175: 13 people detected\n",
      "Frame 176: 11 people detected\n",
      "Frame 177: 16 people detected\n",
      "Frame 178: 13 people detected\n",
      "Frame 179: 13 people detected\n",
      "Frame 180: 12 people detected\n",
      "Frame 181: 18 people detected\n",
      "Frame 182: 18 people detected\n",
      "Frame 183: 14 people detected\n",
      "Frame 184: 18 people detected\n",
      "Frame 185: 15 people detected\n",
      "Frame 186: 15 people detected\n",
      "Frame 187: 15 people detected\n",
      "Frame 188: 11 people detected\n",
      "Frame 189: 12 people detected\n",
      "Frame 190: 16 people detected\n",
      "Frame 191: 13 people detected\n",
      "Frame 192: 13 people detected\n",
      "Frame 193: 14 people detected\n",
      "Frame 194: 14 people detected\n",
      "Frame 195: 16 people detected\n",
      "Frame 196: 18 people detected\n",
      "Frame 197: 17 people detected\n",
      "Frame 198: 18 people detected\n",
      "Frame 199: 14 people detected\n",
      "Frame 200: 15 people detected\n",
      "Frame 201: 14 people detected\n",
      "Frame 202: 13 people detected\n",
      "Frame 203: 15 people detected\n",
      "Frame 204: 15 people detected\n",
      "Frame 205: 15 people detected\n",
      "Frame 206: 16 people detected\n",
      "Frame 207: 18 people detected\n",
      "Frame 208: 15 people detected\n",
      "Frame 209: 19 people detected\n",
      "Frame 210: 17 people detected\n",
      "Frame 211: 17 people detected\n",
      "Frame 212: 17 people detected\n",
      "Frame 213: 15 people detected\n",
      "Frame 214: 18 people detected\n",
      "Frame 215: 17 people detected\n",
      "Frame 216: 11 people detected\n",
      "Frame 217: 11 people detected\n",
      "Frame 218: 13 people detected\n",
      "Frame 219: 9 people detected\n",
      "Frame 220: 18 people detected\n",
      "Frame 221: 12 people detected\n",
      "Frame 222: 14 people detected\n",
      "Frame 223: 16 people detected\n",
      "Frame 224: 15 people detected\n",
      "Frame 225: 13 people detected\n",
      "Frame 226: 17 people detected\n",
      "Frame 227: 13 people detected\n",
      "Frame 228: 13 people detected\n",
      "Frame 229: 16 people detected\n",
      "Frame 230: 14 people detected\n",
      "Frame 231: 12 people detected\n",
      "Frame 232: 15 people detected\n",
      "Frame 233: 14 people detected\n",
      "Frame 234: 16 people detected\n",
      "Frame 235: 15 people detected\n",
      "Frame 236: 14 people detected\n",
      "Frame 237: 13 people detected\n",
      "Frame 238: 12 people detected\n",
      "Frame 239: 9 people detected\n",
      "Frame 240: 9 people detected\n",
      "Frame 241: 12 people detected\n",
      "Frame 242: 16 people detected\n",
      "Frame 243: 14 people detected\n",
      "Frame 244: 13 people detected\n",
      "Frame 245: 11 people detected\n",
      "Frame 246: 11 people detected\n",
      "Frame 247: 11 people detected\n",
      "Frame 248: 9 people detected\n",
      "Frame 249: 9 people detected\n",
      "Frame 250: 11 people detected\n",
      "Frame 251: 13 people detected\n",
      "Frame 252: 12 people detected\n",
      "Frame 253: 15 people detected\n",
      "Frame 254: 14 people detected\n",
      "Frame 255: 12 people detected\n",
      "Frame 256: 14 people detected\n",
      "Frame 257: 14 people detected\n",
      "Frame 258: 10 people detected\n",
      "Frame 259: 12 people detected\n",
      "Frame 260: 11 people detected\n",
      "Frame 261: 13 people detected\n",
      "Frame 262: 11 people detected\n",
      "Frame 263: 13 people detected\n",
      "Frame 264: 11 people detected\n",
      "Frame 265: 11 people detected\n",
      "Frame 266: 10 people detected\n",
      "Frame 267: 9 people detected\n",
      "Frame 268: 8 people detected\n",
      "Frame 269: 7 people detected\n",
      "Frame 270: 7 people detected\n",
      "Frame 271: 8 people detected\n",
      "Frame 272: 6 people detected\n",
      "Frame 273: 6 people detected\n",
      "Frame 274: 8 people detected\n",
      "Frame 275: 8 people detected\n",
      "Frame 276: 8 people detected\n",
      "Frame 277: 8 people detected\n",
      "Frame 278: 8 people detected\n",
      "Frame 279: 5 people detected\n",
      "Frame 280: 5 people detected\n",
      "Frame 281: 7 people detected\n",
      "Frame 282: 7 people detected\n",
      "Frame 283: 7 people detected\n",
      "Frame 284: 9 people detected\n",
      "Frame 285: 9 people detected\n",
      "Frame 286: 8 people detected\n",
      "Frame 287: 8 people detected\n",
      "Frame 288: 10 people detected\n",
      "Frame 289: 8 people detected\n",
      "Frame 290: 5 people detected\n",
      "Frame 291: 8 people detected\n",
      "Frame 292: 5 people detected\n",
      "Frame 293: 4 people detected\n",
      "Frame 294: 5 people detected\n",
      "Frame 295: 6 people detected\n",
      "Frame 296: 7 people detected\n",
      "Frame 297: 5 people detected\n",
      "Frame 298: 7 people detected\n",
      "Frame 299: 8 people detected\n",
      "Frame 300: 8 people detected\n",
      "Frame 301: 11 people detected\n",
      "Frame 302: 9 people detected\n",
      "Frame 303: 9 people detected\n",
      "Frame 304: 10 people detected\n",
      "Frame 305: 8 people detected\n",
      "Frame 306: 9 people detected\n",
      "Frame 307: 11 people detected\n",
      "Frame 308: 8 people detected\n",
      "Frame 309: 11 people detected\n",
      "Frame 310: 10 people detected\n",
      "Frame 311: 9 people detected\n",
      "Frame 312: 11 people detected\n",
      "Frame 313: 9 people detected\n",
      "Frame 314: 9 people detected\n",
      "Frame 315: 7 people detected\n",
      "Frame 316: 9 people detected\n",
      "Frame 317: 10 people detected\n",
      "Frame 318: 9 people detected\n",
      "Frame 319: 8 people detected\n",
      "Frame 320: 7 people detected\n",
      "Frame 321: 8 people detected\n",
      "Frame 322: 4 people detected\n",
      "Frame 323: 6 people detected\n",
      "Frame 324: 4 people detected\n",
      "Frame 325: 6 people detected\n",
      "Frame 326: 7 people detected\n",
      "Frame 327: 8 people detected\n",
      "Frame 328: 7 people detected\n",
      "Frame 329: 8 people detected\n",
      "Frame 330: 5 people detected\n",
      "Frame 331: 5 people detected\n",
      "Frame 332: 4 people detected\n",
      "Frame 333: 5 people detected\n",
      "Frame 334: 4 people detected\n",
      "Frame 335: 6 people detected\n",
      "Frame 336: 5 people detected\n",
      "Frame 337: 8 people detected\n",
      "Frame 338: 7 people detected\n",
      "Frame 339: 7 people detected\n",
      "Frame 340: 7 people detected\n",
      "Frame 341: 6 people detected\n",
      "Frame 342: 6 people detected\n",
      "Frame 343: 8 people detected\n",
      "Frame 344: 14 people detected\n",
      "Frame 345: 15 people detected\n",
      "Frame 346: 13 people detected\n",
      "Frame 347: 11 people detected\n",
      "Frame 348: 12 people detected\n",
      "Frame 349: 14 people detected\n",
      "Frame 350: 11 people detected\n",
      "Frame 351: 11 people detected\n",
      "Frame 352: 12 people detected\n",
      "Frame 353: 8 people detected\n",
      "Frame 354: 7 people detected\n",
      "Frame 355: 8 people detected\n",
      "Frame 356: 9 people detected\n",
      "Frame 357: 8 people detected\n",
      "üõë Stopped by user\n",
      "\n",
      "üìä PLAYBACK COMPLETE:\n",
      "   Frames processed: 357\n",
      "   Playback time: 44.4s\n",
      "   Maximum people in frame: 22\n",
      "   Minimum people in frame: 4\n",
      "   Average people per frame: 12.09\n",
      "\n",
      "üéâ READY TO USE!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VideoPersonCounter:\n",
    "    def __init__(self, model_size='n'):\n",
    "        \"\"\"Initialize YOLO model for person counting\"\"\"\n",
    "        print(f\"üöÄ Initializing Video Person Counter...\")\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_name = \"None\"\n",
    "        self.people_counts = []\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.load_model(model_size)\n",
    "        \n",
    "    def load_model(self, model_size):\n",
    "        \"\"\"Load YOLO model with error handling\"\"\"\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            # Try different model options\n",
    "            model_options = [f'yolo11{model_size}.pt', f'yolov8{model_size}.pt', 'yolo11n.pt', 'yolov8n.pt']\n",
    "            \n",
    "            for model_path in model_options:\n",
    "                try:\n",
    "                    print(f\"üì• Trying to load {model_path}...\")\n",
    "                    self.model = YOLO(model_path)\n",
    "                    self.model.conf = 0.5       # Confidence threshold\n",
    "                    self.model.iou = 0.45       # IoU threshold\n",
    "                    self.model.max_det = 1000   # Max detections\n",
    "                    self.model_name = model_path\n",
    "                    print(f\"‚úÖ Successfully loaded {model_path}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to load {model_path}: {str(e)[:50]}...\")\n",
    "                    continue\n",
    "            \n",
    "            print(\"‚ùå All YOLO models failed to load\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå Ultralytics not installed. Run: pip install ultralytics\")\n",
    "    \n",
    "    def count_people_in_frame(self, frame):\n",
    "        \"\"\"Count people in a single frame\"\"\"\n",
    "        if self.model is None:\n",
    "            return 0, []\n",
    "        \n",
    "        try:\n",
    "            # Run YOLO detection - only detect people (class 0)\n",
    "            results = self.model(frame, classes=[0], verbose=False)\n",
    "            \n",
    "            # Check if results are valid\n",
    "            if not results or len(results) == 0 or results[0].boxes is None:\n",
    "                return 0, []\n",
    "            \n",
    "            # Extract detection data\n",
    "            boxes = results[0].boxes\n",
    "            coords = boxes.xyxy.cpu().numpy()\n",
    "            confs = boxes.conf.cpu().numpy()\n",
    "            \n",
    "            if len(coords) == 0:\n",
    "                return 0, []\n",
    "            \n",
    "            # Create detection info\n",
    "            people_detections = []\n",
    "            for i in range(len(coords)):\n",
    "                box = coords[i].astype(int)\n",
    "                conf = float(confs[i])\n",
    "                \n",
    "                people_detections.append({\n",
    "                    'box': box,\n",
    "                    'confidence': conf,\n",
    "                    'center': ((box[0] + box[2]) // 2, (box[1] + box[3]) // 2)\n",
    "                })\n",
    "            \n",
    "            return len(people_detections), people_detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Detection error: {e}\")\n",
    "            return 0, []\n",
    "    \n",
    "    def draw_people_count_overlay(self, frame, people_count, people_detections):\n",
    "        \"\"\"Draw people count in left corner and bounding boxes\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # LEFT CORNER: Semi-transparent background for count display\n",
    "        overlay = annotated_frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (350, 140), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)\n",
    "        \n",
    "        # Main people count display (LEFT CORNER)\n",
    "        cv2.putText(annotated_frame, 'PEOPLE COUNT', (20, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(annotated_frame, str(people_count), (20, 85),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 2.2, (0, 255, 0), 3)\n",
    "        \n",
    "        # Statistics in left corner\n",
    "        if self.people_counts:\n",
    "            max_people = max(self.people_counts)\n",
    "            avg_people = np.mean(self.people_counts)\n",
    "            cv2.putText(annotated_frame, f'Max: {max_people} | Avg: {avg_people:.1f}', \n",
    "                       (20, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)\n",
    "        \n",
    "        # Draw bounding boxes around each detected person\n",
    "        for detection in people_detections:\n",
    "            box = detection['box']\n",
    "            conf = detection['confidence']\n",
    "            \n",
    "            # Green rectangle around person\n",
    "            cv2.rectangle(annotated_frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "            \n",
    "            # Confidence score above box\n",
    "            cv2.putText(annotated_frame, f'{conf:.2f}', (box[0], box[1]-8),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Center point\n",
    "            center = detection['center']\n",
    "            cv2.circle(annotated_frame, center, 4, (255, 0, 0), -1)\n",
    "        \n",
    "        # Model info (bottom)\n",
    "        cv2.putText(annotated_frame, f'Model: {self.model_name}', \n",
    "                   (20, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def play_video_with_counting(self, video_path):\n",
    "        \"\"\"Play video with live people counting\"\"\"\n",
    "        \n",
    "        print(f\"üé• Opening video: {video_path}\")\n",
    "        \n",
    "        # Open video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "            print(\"üí° Make sure the file exists and is a valid video format (.mp4, .avi, .mov)\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 25\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        print(f\"üìπ Video Info: {width}x{height}, {fps} FPS, {total_frames} frames, {duration:.1f}s\")\n",
    "        print(f\"üé¨ Starting playback with people counting...\")\n",
    "        print(\"Press 'q' to quit, SPACE to pause/resume\")\n",
    "        \n",
    "        # Reset statistics\n",
    "        self.people_counts = []\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        frame_number = 0\n",
    "        start_time = time.time()\n",
    "        paused = False\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if not paused:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"üìπ Video completed!\")\n",
    "                        break\n",
    "                    \n",
    "                    frame_number += 1\n",
    "                    \n",
    "                    # Count people in current frame\n",
    "                    people_count, people_detections = self.count_people_in_frame(frame)\n",
    "                    \n",
    "                    # Update statistics\n",
    "                    self.people_counts.append(people_count)\n",
    "                    self.frame_count += 1\n",
    "                    \n",
    "                    # PRINT PEOPLE COUNT FOR EACH FRAME (as requested)\n",
    "                    print(f\"Frame {frame_number}: {people_count} people detected\")\n",
    "                    \n",
    "                    # Draw count overlay and bounding boxes\n",
    "                    display_frame = self.draw_people_count_overlay(frame, people_count, people_detections)\n",
    "                    \n",
    "                    # Add progress info\n",
    "                    progress = (frame_number / total_frames) * 100\n",
    "                    timestamp = frame_number / fps\n",
    "                    cv2.putText(display_frame, f'Progress: {progress:.1f}%', \n",
    "                               (width - 200, height - 60),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                    cv2.putText(display_frame, f'Time: {timestamp:.1f}s', \n",
    "                               (width - 200, height - 30),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # Display the frame\n",
    "                cv2.imshow('Video Person Counter', display_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(30) & 0xFF  # 30ms delay for smooth playback\n",
    "                \n",
    "                if key == ord('q') or key == 27:  # 'q' or ESC to quit\n",
    "                    print(\"üõë Stopped by user\")\n",
    "                    break\n",
    "                elif key == ord(' '):  # SPACE to pause/resume\n",
    "                    paused = not paused\n",
    "                    print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "                elif key == ord('s'):  # 's' to save screenshot\n",
    "                    screenshot_name = f\"screenshot_frame_{frame_number}.jpg\"\n",
    "                    cv2.imwrite(screenshot_name, display_frame)\n",
    "                    print(f\"üì∏ Screenshot saved: {screenshot_name}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Playback interrupted by user (Ctrl+C)\")\n",
    "        \n",
    "        finally:\n",
    "            # Cleanup\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Final statistics\n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            if self.people_counts:\n",
    "                print(f\"\\nüìä PLAYBACK COMPLETE:\")\n",
    "                print(f\"   Frames processed: {self.frame_count}\")\n",
    "                print(f\"   Playback time: {total_time:.1f}s\")\n",
    "                print(f\"   Maximum people in frame: {max(self.people_counts)}\")\n",
    "                print(f\"   Minimum people in frame: {min(self.people_counts)}\")\n",
    "                print(f\"   Average people per frame: {np.mean(self.people_counts):.2f}\")\n",
    "\n",
    "# Initialize and use the counter\n",
    "print(\"üöÄ INITIALIZING VIDEO PERSON COUNTER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create counter instance\n",
    "    counter = VideoPersonCounter('n')  # 'n' = nano (fastest), 's' = small, 'm' = medium\n",
    "    \n",
    "    print(\"\\n‚úÖ INITIALIZATION SUCCESSFUL!\")\n",
    "    print(f\"üì± Model: {counter.model_name}\")\n",
    "    \n",
    "    print(f\"\\nüéØ READY TO PLAY VIDEO WITH PEOPLE COUNTING!\")\n",
    "    print(f\"\\nüé¨ CONTROLS:\")\n",
    "    print(f\"   'q' or ESC = Quit\")\n",
    "    print(f\"   SPACE = Pause/Resume\")\n",
    "    print(f\"   's' = Save screenshot\")\n",
    "    \n",
    "    # Play your video (replace with your video file path)\n",
    "    counter.play_video_with_counting('testing8.mp4')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° TROUBLESHOOTING:\")\n",
    "    print(\"1. Install system dependencies: sudo apt-get install -y libgl1-mesa-glx libglib2.0-0\")\n",
    "    print(\"2. Install ultralytics: pip install ultralytics\")\n",
    "    print(\"3. Make sure video file exists and is in correct format\")\n",
    "\n",
    "print(\"\\nüéâ READY TO USE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff24033-e64b-4cbc-baeb-d699ffc63f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING FIXED VIDEO PERSON COUNTER\n",
      "=======================================================\n",
      "üöÄ Initializing Video Person Counter...\n",
      "‚úÖ OpenCV display available\n",
      "üì• Loading yolo11n.pt...\n",
      "‚úÖ Successfully loaded yolo11n.pt\n",
      "\n",
      "‚úÖ INITIALIZATION SUCCESSFUL!\n",
      "üì± Model: yolo11n.pt\n",
      "üì∫ Display method: opencv\n",
      "üé• Opening video: testing8.mp4\n",
      "üìπ Video Info: 1920x1080, 30 FPS, 407 frames, 13.6s\n",
      "üé¨ Starting playback with people counting...\n",
      "üì∫ Display method: opencv\n",
      "Frame 1: 13 people detected\n",
      "Frame 2: 12 people detected\n",
      "Frame 3: 14 people detected\n",
      "Frame 4: 14 people detected\n",
      "Frame 5: 13 people detected\n",
      "Frame 6: 15 people detected\n",
      "Frame 7: 16 people detected\n",
      "Frame 8: 13 people detected\n",
      "Frame 9: 12 people detected\n",
      "Frame 10: 9 people detected\n",
      "Frame 11: 12 people detected\n",
      "Frame 12: 11 people detected\n",
      "Frame 13: 9 people detected\n",
      "Frame 14: 9 people detected\n",
      "Frame 15: 10 people detected\n",
      "Frame 16: 10 people detected\n",
      "Frame 17: 12 people detected\n",
      "Frame 18: 12 people detected\n",
      "Frame 19: 12 people detected\n",
      "Frame 20: 10 people detected\n",
      "Frame 21: 11 people detected\n",
      "Frame 22: 7 people detected\n",
      "Frame 23: 12 people detected\n",
      "Frame 24: 14 people detected\n",
      "Frame 25: 16 people detected\n",
      "Frame 26: 15 people detected\n",
      "Frame 27: 15 people detected\n",
      "Frame 28: 12 people detected\n",
      "Frame 29: 10 people detected\n",
      "Frame 30: 12 people detected\n",
      "Frame 31: 12 people detected\n",
      "Frame 32: 12 people detected\n",
      "Frame 33: 16 people detected\n",
      "Frame 34: 14 people detected\n",
      "Frame 35: 14 people detected\n",
      "Frame 36: 15 people detected\n",
      "Frame 37: 13 people detected\n",
      "Frame 38: 14 people detected\n",
      "Frame 39: 14 people detected\n",
      "Frame 40: 15 people detected\n",
      "Frame 41: 13 people detected\n",
      "Frame 42: 12 people detected\n",
      "Frame 43: 14 people detected\n",
      "Frame 44: 16 people detected\n",
      "Frame 45: 13 people detected\n",
      "Frame 46: 15 people detected\n",
      "Frame 47: 13 people detected\n",
      "Frame 48: 12 people detected\n",
      "Frame 49: 12 people detected\n",
      "Frame 50: 12 people detected\n",
      "Frame 51: 11 people detected\n",
      "Frame 52: 9 people detected\n",
      "Frame 53: 9 people detected\n",
      "Frame 54: 14 people detected\n",
      "Frame 55: 12 people detected\n",
      "Frame 56: 11 people detected\n",
      "Frame 57: 15 people detected\n",
      "Frame 58: 14 people detected\n",
      "Frame 59: 13 people detected\n",
      "Frame 60: 15 people detected\n",
      "Frame 61: 17 people detected\n",
      "Frame 62: 17 people detected\n",
      "Frame 63: 20 people detected\n",
      "Frame 64: 18 people detected\n",
      "Frame 65: 15 people detected\n",
      "Frame 66: 13 people detected\n",
      "Frame 67: 11 people detected\n",
      "Frame 68: 10 people detected\n",
      "Frame 69: 14 people detected\n",
      "Frame 70: 17 people detected\n",
      "Frame 71: 15 people detected\n",
      "üõë Stopped by user\n",
      "\n",
      "üìä PLAYBACK COMPLETE:\n",
      "   Frames processed: 71\n",
      "   Playback time: 11.3s\n",
      "   Maximum people in frame: 20\n",
      "   Minimum people in frame: 7\n",
      "   Average people per frame: 13.00\n",
      "   Display method used: opencv\n",
      "\n",
      "üéâ COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VideoPersonCounterFixed:\n",
    "    def __init__(self, model_size='n'):\n",
    "        print(f\"üöÄ Initializing Video Person Counter...\")\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_name = \"None\"\n",
    "        self.people_counts = []\n",
    "        self.frame_count = 0\n",
    "        self.display_method = \"opencv\"  # Will switch to matplotlib if needed\n",
    "        \n",
    "        # Test display capability\n",
    "        self.test_display()\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.load_model(model_size)\n",
    "        \n",
    "    def test_display(self):\n",
    "        \"\"\"Test if OpenCV display works\"\"\"\n",
    "        try:\n",
    "            test_img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "            cv2.imshow('test_window', test_img)\n",
    "            cv2.waitKey(1)\n",
    "            cv2.destroyWindow('test_window')\n",
    "            self.display_method = \"opencv\"\n",
    "            print(\"‚úÖ OpenCV display available\")\n",
    "        except:\n",
    "            self.display_method = \"matplotlib\"\n",
    "            print(\"‚ö†Ô∏è OpenCV display not available, using matplotlib\")\n",
    "        \n",
    "    def load_model(self, model_size):\n",
    "        \"\"\"Load YOLO model\"\"\"\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            model_options = [f'yolo11{model_size}.pt', f'yolov8{model_size}.pt', 'yolo11n.pt']\n",
    "            \n",
    "            for model_path in model_options:\n",
    "                try:\n",
    "                    print(f\"üì• Loading {model_path}...\")\n",
    "                    self.model = YOLO(model_path)\n",
    "                    self.model.conf = 0.5\n",
    "                    self.model.iou = 0.45\n",
    "                    self.model.max_det = 1000\n",
    "                    self.model_name = model_path\n",
    "                    print(f\"‚úÖ Successfully loaded {model_path}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            print(\"‚ùå Failed to load YOLO model\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå Ultralytics not installed\")\n",
    "    \n",
    "    def count_people_in_frame(self, frame):\n",
    "        \"\"\"Count people in frame\"\"\"\n",
    "        if self.model is None:\n",
    "            return 0, []\n",
    "        \n",
    "        try:\n",
    "            results = self.model(frame, classes=[0], verbose=False)  # Person class only\n",
    "            \n",
    "            if not results or len(results) == 0 or results[0].boxes is None:\n",
    "                return 0, []\n",
    "            \n",
    "            boxes = results[0].boxes\n",
    "            coords = boxes.xyxy.cpu().numpy()\n",
    "            confs = boxes.conf.cpu().numpy()\n",
    "            \n",
    "            if len(coords) == 0:\n",
    "                return 0, []\n",
    "            \n",
    "            people_detections = []\n",
    "            for i in range(len(coords)):\n",
    "                box = coords[i].astype(int)\n",
    "                conf = float(confs[i])\n",
    "                \n",
    "                people_detections.append({\n",
    "                    'box': box,\n",
    "                    'confidence': conf,\n",
    "                    'center': ((box[0] + box[2]) // 2, (box[1] + box[3]) // 2)\n",
    "                })\n",
    "            \n",
    "            return len(people_detections), people_detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Detection error: {e}\")\n",
    "            return 0, []\n",
    "    \n",
    "    def draw_annotations(self, frame, people_count, people_detections):\n",
    "        \"\"\"Draw people count and bounding boxes\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # LEFT CORNER: Semi-transparent background for count display\n",
    "        overlay = annotated_frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (350, 140), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)\n",
    "        \n",
    "        # Main people count display\n",
    "        cv2.putText(annotated_frame, 'PEOPLE COUNT', (20, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "        cv2.putText(annotated_frame, str(people_count), (20, 85),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 2.2, (0, 255, 0), 3)\n",
    "        \n",
    "        # Statistics\n",
    "        if self.people_counts:\n",
    "            max_people = max(self.people_counts)\n",
    "            avg_people = np.mean(self.people_counts)\n",
    "            cv2.putText(annotated_frame, f'Max: {max_people} | Avg: {avg_people:.1f}', \n",
    "                       (20, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 2)\n",
    "        \n",
    "        # Draw bounding boxes around detected people\n",
    "        for detection in people_detections:\n",
    "            box = detection['box']\n",
    "            conf = detection['confidence']\n",
    "            \n",
    "            # Green rectangle around person\n",
    "            cv2.rectangle(annotated_frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "            \n",
    "            # Confidence score\n",
    "            cv2.putText(annotated_frame, f'{conf:.2f}', (box[0], box[1]-8),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Center point\n",
    "            center = detection['center']\n",
    "            cv2.circle(annotated_frame, center, 4, (255, 0, 0), -1)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def display_frame_safe(self, frame, frame_number):\n",
    "        \"\"\"Safe frame display with fallback to matplotlib\"\"\"\n",
    "        \n",
    "        if self.display_method == \"opencv\":\n",
    "            try:\n",
    "                cv2.imshow('Video Person Counter', frame)\n",
    "                key = cv2.waitKey(30) & 0xFF\n",
    "                return key\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è OpenCV display failed: {e}\")\n",
    "                self.display_method = \"matplotlib\"\n",
    "        \n",
    "        # Matplotlib fallback (works everywhere)\n",
    "        if self.display_method == \"matplotlib\":\n",
    "            try:\n",
    "                import matplotlib.pyplot as plt\n",
    "                \n",
    "                # Convert BGR to RGB for matplotlib\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.imshow(frame_rgb)\n",
    "                plt.title(f'Frame {frame_number} - Person Counter')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                return ord('c')  # Continue\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Matplotlib display also failed: {e}\")\n",
    "                # Just continue without display\n",
    "                return ord('c')\n",
    "        \n",
    "        return ord('c')\n",
    "    \n",
    "    def play_video_with_counting(self, video_path, display_video=True, save_frames=False):\n",
    "        \"\"\"Play video with people counting - handles display issues gracefully\"\"\"\n",
    "        \n",
    "        print(f\"üé• Opening video: {video_path}\")\n",
    "        \n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 25\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  \n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        print(f\"üìπ Video Info: {width}x{height}, {fps} FPS, {total_frames} frames, {duration:.1f}s\")\n",
    "        print(f\"üé¨ Starting playback with people counting...\")\n",
    "        print(f\"üì∫ Display method: {self.display_method}\")\n",
    "        \n",
    "        # Reset statistics\n",
    "        self.people_counts = []\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        frame_number = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"üìπ Video completed!\")\n",
    "                    break\n",
    "                \n",
    "                frame_number += 1\n",
    "                \n",
    "                # Count people in current frame\n",
    "                people_count, people_detections = self.count_people_in_frame(frame)\n",
    "                \n",
    "                # Update statistics\n",
    "                self.people_counts.append(people_count)\n",
    "                self.frame_count += 1\n",
    "                \n",
    "                # PRINT PEOPLE COUNT FOR EACH FRAME (as requested)\n",
    "                print(f\"Frame {frame_number}: {people_count} people detected\")\n",
    "                \n",
    "                # Draw annotations\n",
    "                display_frame = self.draw_annotations(frame, people_count, people_detections)\n",
    "                \n",
    "                # Add progress info\n",
    "                progress = (frame_number / total_frames) * 100\n",
    "                timestamp = frame_number / fps\n",
    "                cv2.putText(display_frame, f'Progress: {progress:.1f}%', \n",
    "                           (width - 200, height - 60),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                cv2.putText(display_frame, f'Time: {timestamp:.1f}s', \n",
    "                           (width - 200, height - 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # Display frame (handles both OpenCV and matplotlib)\n",
    "                if display_video:\n",
    "                    key = self.display_frame_safe(display_frame, frame_number)\n",
    "                    \n",
    "                    if key == ord('q') or key == 27:  # 'q' or ESC to quit\n",
    "                        print(\"üõë Stopped by user\")\n",
    "                        break\n",
    "                \n",
    "                # Save frames if requested\n",
    "                if save_frames and frame_number % 30 == 0:  # Save every 30th frame\n",
    "                    cv2.imwrite(f\"frame_{frame_number:04d}_people_{people_count}.jpg\", display_frame)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Playback interrupted by user (Ctrl+C)\")\n",
    "        \n",
    "        finally:\n",
    "            # Safe cleanup\n",
    "            cap.release()\n",
    "            try:\n",
    "                if self.display_method == \"opencv\":\n",
    "                    cv2.destroyAllWindows()\n",
    "            except:\n",
    "                pass  # Ignore cleanup errors\n",
    "            \n",
    "            # Final statistics\n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            if self.people_counts:\n",
    "                print(f\"\\nüìä PLAYBACK COMPLETE:\")\n",
    "                print(f\"   Frames processed: {self.frame_count}\")\n",
    "                print(f\"   Playback time: {total_time:.1f}s\")\n",
    "                print(f\"   Maximum people in frame: {max(self.people_counts)}\")\n",
    "                print(f\"   Minimum people in frame: {min(self.people_counts)}\")\n",
    "                print(f\"   Average people per frame: {np.mean(self.people_counts):.2f}\")\n",
    "                print(f\"   Display method used: {self.display_method}\")\n",
    "\n",
    "# Initialize and use the fixed counter\n",
    "print(\"üöÄ INITIALIZING FIXED VIDEO PERSON COUNTER\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "try:\n",
    "    # Create counter with display fallback\n",
    "    counter = VideoPersonCounterFixed('n')\n",
    "    \n",
    "    print(\"\\n‚úÖ INITIALIZATION SUCCESSFUL!\")\n",
    "    print(f\"üì± Model: {counter.model_name}\")\n",
    "    print(f\"üì∫ Display method: {counter.display_method}\")\n",
    "    \n",
    "    # Play your video with safe display handling\n",
    "    counter.play_video_with_counting('testing8.mp4', display_video=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ COMPLETE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace75903-2c85-4dbc-8e70-b2532f3bcc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING COMPLETE VIDEO PERSON COUNTER\n",
      "=======================================================\n",
      "üöÄ Initializing Video Person Counter...\n",
      "üì• Trying to load yolo11n.pt...\n",
      "‚úÖ Successfully loaded yolo11n.pt\n",
      "\n",
      "‚úÖ INITIALIZATION SUCCESSFUL!\n",
      "üì± Model: yolo11n.pt\n",
      "üñ•Ô∏è Max display size: 1200x800\n",
      "\n",
      "üéØ READY TO PLAY COMPLETE VIDEO WITH PEOPLE COUNTING!\n",
      "\n",
      "üé¨ CONTROLS:\n",
      "   'q' or ESC = Quit\n",
      "   SPACE = Pause/Resume\n",
      "   'f' = Fullscreen\n",
      "   'n' = Normal window\n",
      "   's' = Save screenshot\n",
      "üé• Opening video: testing8.mp4\n",
      "üì∫ Display scaling: 1920x1080 ‚Üí 1200x675 (scale: 0.62)\n",
      "üìπ Video Info: 1920x1080, 30 FPS, 407 frames, 13.6s\n",
      "üé¨ Starting playback with complete video display...\n",
      "Press 'q' to quit, SPACE to pause/resume, 'f' for fullscreen\n",
      "Frame 1: 13 people detected\n",
      "Frame 2: 12 people detected\n",
      "Frame 3: 14 people detected\n",
      "Frame 4: 14 people detected\n",
      "Frame 5: 13 people detected\n",
      "Frame 6: 15 people detected\n",
      "Frame 7: 16 people detected\n",
      "Frame 8: 13 people detected\n",
      "Frame 9: 12 people detected\n",
      "Frame 10: 9 people detected\n",
      "Frame 11: 12 people detected\n",
      "Frame 12: 11 people detected\n",
      "Frame 13: 9 people detected\n",
      "Frame 14: 9 people detected\n",
      "Frame 15: 10 people detected\n",
      "Frame 16: 10 people detected\n",
      "Frame 17: 12 people detected\n",
      "Frame 18: 12 people detected\n",
      "Frame 19: 12 people detected\n",
      "Frame 20: 10 people detected\n",
      "Frame 21: 11 people detected\n",
      "Frame 22: 7 people detected\n",
      "Frame 23: 12 people detected\n",
      "Frame 24: 14 people detected\n",
      "Frame 25: 16 people detected\n",
      "Frame 26: 15 people detected\n",
      "Frame 27: 15 people detected\n",
      "Frame 28: 12 people detected\n",
      "Frame 29: 10 people detected\n",
      "Frame 30: 12 people detected\n",
      "Frame 31: 12 people detected\n",
      "Frame 32: 12 people detected\n",
      "Frame 33: 16 people detected\n",
      "Frame 34: 14 people detected\n",
      "Frame 35: 14 people detected\n",
      "Frame 36: 15 people detected\n",
      "Frame 37: 13 people detected\n",
      "Frame 38: 14 people detected\n",
      "Frame 39: 14 people detected\n",
      "Frame 40: 15 people detected\n",
      "Frame 41: 13 people detected\n",
      "Frame 42: 12 people detected\n",
      "Frame 43: 14 people detected\n",
      "Frame 44: 16 people detected\n",
      "Frame 45: 13 people detected\n",
      "Frame 46: 15 people detected\n",
      "Frame 47: 13 people detected\n",
      "Frame 48: 12 people detected\n",
      "Frame 49: 12 people detected\n",
      "Frame 50: 12 people detected\n",
      "Frame 51: 11 people detected\n",
      "Frame 52: 9 people detected\n",
      "Frame 53: 9 people detected\n",
      "Frame 54: 14 people detected\n",
      "Frame 55: 12 people detected\n",
      "Frame 56: 11 people detected\n",
      "Frame 57: 15 people detected\n",
      "Frame 58: 14 people detected\n",
      "Frame 59: 13 people detected\n",
      "Frame 60: 15 people detected\n",
      "Frame 61: 17 people detected\n",
      "Frame 62: 17 people detected\n",
      "Frame 63: 20 people detected\n",
      "üõë Stopped by user\n",
      "\n",
      "üìä PLAYBACK COMPLETE:\n",
      "   Original video: 1920x1080\n",
      "   Display size: 1200x675\n",
      "   Scale factor: 0.62\n",
      "   Frames processed: 63\n",
      "   Playback time: 8.9s\n",
      "   Maximum people in frame: 20\n",
      "   Minimum people in frame: 7\n",
      "   Average people per frame: 12.86\n",
      "\n",
      "üéâ COMPLETE VIDEO DISPLAY READY!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VideoPersonCounter:\n",
    "    def __init__(self, model_size='n'):\n",
    "        \"\"\"Initialize YOLO model for person counting\"\"\"\n",
    "        print(f\"üöÄ Initializing Video Person Counter...\")\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_name = \"None\"\n",
    "        self.people_counts = []\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # Screen dimensions (adjust these to your screen size)\n",
    "        self.max_display_width = 1200   # Maximum window width\n",
    "        self.max_display_height = 800   # Maximum window height\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.load_model(model_size)\n",
    "        \n",
    "    def load_model(self, model_size):\n",
    "        \"\"\"Load YOLO model with error handling\"\"\"\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            # Try different model options\n",
    "            model_options = [f'yolo11{model_size}.pt', f'yolov8{model_size}.pt', 'yolo11n.pt', 'yolov8n.pt']\n",
    "            \n",
    "            for model_path in model_options:\n",
    "                try:\n",
    "                    print(f\"üì• Trying to load {model_path}...\")\n",
    "                    self.model = YOLO(model_path)\n",
    "                    self.model.conf = 0.5       # Confidence threshold\n",
    "                    self.model.iou = 0.45       # IoU threshold\n",
    "                    self.model.max_det = 1000   # Max detections\n",
    "                    self.model_name = model_path\n",
    "                    print(f\"‚úÖ Successfully loaded {model_path}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to load {model_path}: {str(e)[:50]}...\")\n",
    "                    continue\n",
    "            \n",
    "            print(\"‚ùå All YOLO models failed to load\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå Ultralytics not installed. Run: pip install ultralytics\")\n",
    "    \n",
    "    def calculate_display_size(self, video_width, video_height):\n",
    "        \"\"\"Calculate optimal display size to show complete video\"\"\"\n",
    "        \n",
    "        # Calculate scaling factor to fit video within max display dimensions\n",
    "        scale_width = self.max_display_width / video_width\n",
    "        scale_height = self.max_display_height / video_height\n",
    "        \n",
    "        # Use the smaller scale to ensure the entire video fits\n",
    "        scale_factor = min(scale_width, scale_height, 1.0)  # Don't scale up\n",
    "        \n",
    "        # Calculate new dimensions\n",
    "        display_width = int(video_width * scale_factor)\n",
    "        display_height = int(video_height * scale_factor)\n",
    "        \n",
    "        print(f\"üì∫ Display scaling: {video_width}x{video_height} ‚Üí {display_width}x{display_height} (scale: {scale_factor:.2f})\")\n",
    "        \n",
    "        return display_width, display_height, scale_factor\n",
    "    \n",
    "    def count_people_in_frame(self, frame):\n",
    "        \"\"\"Count people in a single frame\"\"\"\n",
    "        if self.model is None:\n",
    "            return 0, []\n",
    "        \n",
    "        try:\n",
    "            # Run YOLO detection - only detect people (class 0)\n",
    "            results = self.model(frame, classes=[0], verbose=False)\n",
    "            \n",
    "            # Check if results are valid\n",
    "            if not results or len(results) == 0 or results[0].boxes is None:\n",
    "                return 0, []\n",
    "            \n",
    "            # Extract detection data\n",
    "            boxes = results[0].boxes\n",
    "            coords = boxes.xyxy.cpu().numpy()\n",
    "            confs = boxes.conf.cpu().numpy()\n",
    "            \n",
    "            if len(coords) == 0:\n",
    "                return 0, []\n",
    "            \n",
    "            # Create detection info\n",
    "            people_detections = []\n",
    "            for i in range(len(coords)):\n",
    "                box = coords[i].astype(int)\n",
    "                conf = float(confs[i])\n",
    "                \n",
    "                people_detections.append({\n",
    "                    'box': box,\n",
    "                    'confidence': conf,\n",
    "                    'center': ((box[0] + box[2]) // 2, (box[1] + box[3]) // 2)\n",
    "                })\n",
    "            \n",
    "            return len(people_detections), people_detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Detection error: {e}\")\n",
    "            return 0, []\n",
    "    \n",
    "    def draw_people_count_overlay(self, frame, people_count, people_detections, scale_factor=1.0):\n",
    "        \"\"\"Draw people count in left corner and bounding boxes with proper scaling\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Scale elements based on display size\n",
    "        font_scale = max(0.4, scale_factor * 0.8)\n",
    "        thickness = max(1, int(scale_factor * 2))\n",
    "        \n",
    "        # LEFT CORNER: Semi-transparent background for count display\n",
    "        overlay = annotated_frame.copy()\n",
    "        rect_width = int(350 * scale_factor)\n",
    "        rect_height = int(140 * scale_factor)\n",
    "        cv2.rectangle(overlay, (10, 10), (10 + rect_width, 10 + rect_height), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)\n",
    "        \n",
    "        # Main people count display (LEFT CORNER)\n",
    "        cv2.putText(annotated_frame, 'PEOPLE COUNT', (20, int(40 * scale_factor)),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)\n",
    "        cv2.putText(annotated_frame, str(people_count), (20, int(85 * scale_factor)),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 2.5, (0, 255, 0), thickness + 1)\n",
    "        \n",
    "        # Statistics in left corner\n",
    "        if self.people_counts:\n",
    "            max_people = max(self.people_counts)\n",
    "            avg_people = np.mean(self.people_counts)\n",
    "            cv2.putText(annotated_frame, f'Max: {max_people} | Avg: {avg_people:.1f}', \n",
    "                       (20, int(125 * scale_factor)), cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.8, (200, 200, 200), thickness)\n",
    "        \n",
    "        # Draw bounding boxes around each detected person\n",
    "        for detection in people_detections:\n",
    "            box = detection['box']\n",
    "            conf = detection['confidence']\n",
    "            \n",
    "            # Green rectangle around person\n",
    "            cv2.rectangle(annotated_frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), thickness)\n",
    "            \n",
    "            # Confidence score above box\n",
    "            cv2.putText(annotated_frame, f'{conf:.2f}', (box[0], box[1]-8),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (0, 255, 0), thickness)\n",
    "            \n",
    "            # Center point\n",
    "            center = detection['center']\n",
    "            cv2.circle(annotated_frame, center, max(2, int(4 * scale_factor)), (255, 0, 0), -1)\n",
    "        \n",
    "        # Model info (bottom)\n",
    "        cv2.putText(annotated_frame, f'Model: {self.model_name}', \n",
    "                   (20, h - int(20 * scale_factor)), cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.8, (255, 255, 255), thickness)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def play_video_with_counting(self, video_path):\n",
    "        \"\"\"Play video with live people counting - COMPLETE VIDEO DISPLAY\"\"\"\n",
    "        \n",
    "        print(f\"üé• Opening video: {video_path}\")\n",
    "        \n",
    "        # Open video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "            print(\"üí° Make sure the file exists and is a valid video format (.mp4, .avi, .mov)\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 25\n",
    "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        # Calculate display dimensions to show complete video\n",
    "        display_width, display_height, scale_factor = self.calculate_display_size(\n",
    "            original_width, original_height\n",
    "        )\n",
    "        \n",
    "        print(f\"üìπ Video Info: {original_width}x{original_height}, {fps} FPS, {total_frames} frames, {duration:.1f}s\")\n",
    "        print(f\"üé¨ Starting playback with complete video display...\")\n",
    "        print(\"Press 'q' to quit, SPACE to pause/resume, 'f' for fullscreen\")\n",
    "        \n",
    "        # Create resizable window for complete video display\n",
    "        cv2.namedWindow('Complete Video Person Counter', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Complete Video Person Counter', display_width, display_height)\n",
    "        \n",
    "        # Reset statistics\n",
    "        self.people_counts = []\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        frame_number = 0\n",
    "        start_time = time.time()\n",
    "        paused = False\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if not paused:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"üìπ Video completed!\")\n",
    "                        break\n",
    "                    \n",
    "                    frame_number += 1\n",
    "                    \n",
    "                    # Count people in ORIGINAL frame (better accuracy)\n",
    "                    people_count, people_detections = self.count_people_in_frame(frame)\n",
    "                    \n",
    "                    # Update statistics\n",
    "                    self.people_counts.append(people_count)\n",
    "                    self.frame_count += 1\n",
    "                    \n",
    "                    # PRINT PEOPLE COUNT FOR EACH FRAME (as requested)\n",
    "                    print(f\"Frame {frame_number}: {people_count} people detected\")\n",
    "                    \n",
    "                    # Draw count overlay and bounding boxes on original frame\n",
    "                    display_frame = self.draw_people_count_overlay(frame, people_count, people_detections, scale_factor)\n",
    "                    \n",
    "                    # Add progress info (scaled for original resolution)\n",
    "                    progress = (frame_number / total_frames) * 100\n",
    "                    timestamp = frame_number / fps\n",
    "                    cv2.putText(display_frame, f'Progress: {progress:.1f}%', \n",
    "                               (original_width - int(200 * scale_factor), original_height - int(60 * scale_factor)),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, scale_factor * 0.6, (255, 255, 255), max(1, int(scale_factor * 2)))\n",
    "                    cv2.putText(display_frame, f'Time: {timestamp:.1f}s', \n",
    "                               (original_width - int(200 * scale_factor), original_height - int(30 * scale_factor)),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, scale_factor * 0.6, (255, 255, 255), max(1, int(scale_factor * 2)))\n",
    "                    \n",
    "                    # Resize frame for display (this shows the COMPLETE video)\n",
    "                    resized_display_frame = cv2.resize(display_frame, (display_width, display_height))\n",
    "                \n",
    "                # Display the COMPLETE resized frame\n",
    "                cv2.imshow('Complete Video Person Counter', resized_display_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(max(1, int(1000/fps))) & 0xFF  # Match video FPS\n",
    "                \n",
    "                if key == ord('q') or key == 27:  # 'q' or ESC to quit\n",
    "                    print(\"üõë Stopped by user\")\n",
    "                    break\n",
    "                elif key == ord(' '):  # SPACE to pause/resume\n",
    "                    paused = not paused\n",
    "                    print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "                elif key == ord('f'):  # 'f' for fullscreen\n",
    "                    cv2.setWindowProperty('Complete Video Person Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "                    print(\"üîç Fullscreen mode\")\n",
    "                elif key == ord('n'):  # 'n' for normal window\n",
    "                    cv2.setWindowProperty('Complete Video Person Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "                    print(\"üì∫ Normal window mode\")\n",
    "                elif key == ord('s'):  # 's' to save screenshot\n",
    "                    screenshot_name = f\"screenshot_frame_{frame_number}.jpg\"\n",
    "                    cv2.imwrite(screenshot_name, resized_display_frame)\n",
    "                    print(f\"üì∏ Screenshot saved: {screenshot_name}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Playback interrupted by user (Ctrl+C)\")\n",
    "        \n",
    "        finally:\n",
    "            # Cleanup\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Final statistics\n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            if self.people_counts:\n",
    "                print(f\"\\nüìä PLAYBACK COMPLETE:\")\n",
    "                print(f\"   Original video: {original_width}x{original_height}\")\n",
    "                print(f\"   Display size: {display_width}x{display_height}\")\n",
    "                print(f\"   Scale factor: {scale_factor:.2f}\")\n",
    "                print(f\"   Frames processed: {self.frame_count}\")\n",
    "                print(f\"   Playback time: {total_time:.1f}s\")\n",
    "                print(f\"   Maximum people in frame: {max(self.people_counts)}\")\n",
    "                print(f\"   Minimum people in frame: {min(self.people_counts)}\")\n",
    "                print(f\"   Average people per frame: {np.mean(self.people_counts):.2f}\")\n",
    "\n",
    "# Initialize and use the counter\n",
    "print(\"üöÄ INITIALIZING COMPLETE VIDEO PERSON COUNTER\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "try:\n",
    "    # Create counter instance\n",
    "    counter = VideoPersonCounter('n')  # 'n' = nano (fastest), 's' = small, 'm' = medium\n",
    "    \n",
    "    # Adjust these values to match your screen size\n",
    "    counter.max_display_width = 1200    # Change to fit your screen\n",
    "    counter.max_display_height = 800    # Change to fit your screen\n",
    "    \n",
    "    print(\"\\n‚úÖ INITIALIZATION SUCCESSFUL!\")\n",
    "    print(f\"üì± Model: {counter.model_name}\")\n",
    "    print(f\"üñ•Ô∏è Max display size: {counter.max_display_width}x{counter.max_display_height}\")\n",
    "    \n",
    "    print(f\"\\nüéØ READY TO PLAY COMPLETE VIDEO WITH PEOPLE COUNTING!\")\n",
    "    print(f\"\\nüé¨ CONTROLS:\")\n",
    "    print(f\"   'q' or ESC = Quit\")\n",
    "    print(f\"   SPACE = Pause/Resume\")\n",
    "    print(f\"   'f' = Fullscreen\")\n",
    "    print(f\"   'n' = Normal window\")\n",
    "    print(f\"   's' = Save screenshot\")\n",
    "    \n",
    "    # Play your video (replace with your video file path)\n",
    "    counter.play_video_with_counting('testing8.mp4')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° TROUBLESHOOTING:\")\n",
    "    print(\"1. Install system dependencies: sudo apt-get install -y libgl1-mesa-glx libglib2.0-0\")\n",
    "    print(\"2. Install ultralytics: pip install ultralytics\")\n",
    "    print(\"3. Make sure video file exists and is in correct format\")\n",
    "\n",
    "print(\"\\nüéâ COMPLETE VIDEO DISPLAY READY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9824c4af-7233-4119-9bf6-0dfe9c182767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING LINE-BASED PERSON COUNTER\n",
      "============================================================\n",
      "üöÄ Initializing Line-Based Person Counter...\n",
      "üì• Trying to load yolo11n.pt...\n",
      "‚úÖ Successfully loaded yolo11n.pt\n",
      "\n",
      "‚úÖ INITIALIZATION SUCCESSFUL!\n",
      "üì± Model: yolo11n.pt\n",
      "üìè Line position: 90.0% from top\n",
      "\n",
      "üéØ READY FOR LINE-BASED COUNTING!\n",
      "\n",
      "üé¨ CONTROLS:\n",
      "   'q' or ESC = Quit\n",
      "   SPACE = Pause/Resume\n",
      "   'f' = Fullscreen\n",
      "   'n' = Normal window\n",
      "   's' = Save screenshot\n",
      "\n",
      "üìè HOW IT WORKS:\n",
      "   ‚Ä¢ Green horizontal line appears at 90.0% from top\n",
      "   ‚Ä¢ People are counted ONLY when they touch/cross this line\n",
      "   ‚Ä¢ Red boxes = people crossing line, Blue boxes = people not crossing\n",
      "   ‚Ä¢ Total count accumulates for entire video\n",
      "üé• Opening video: testing10.mp4\n",
      "üìπ Video Info: 768x432, 25 FPS, 750 frames, 30.0s\n",
      "üìè Counting line at Y = 388 (90.0% from top)\n",
      "üé¨ Starting line-based counting...\n",
      "Press 'q' to quit, SPACE to pause/resume, 'f' for fullscreen\n",
      "Frame 5: 5 people crossing line | Total: 5\n",
      "Frame 10: 2 people crossing line | Total: 7\n",
      "Frame 15: 1 people crossing line | Total: 8\n",
      "Frame 20: 4 people crossing line | Total: 12\n",
      "Frame 25: 4 people crossing line | Total: 16\n",
      "Frame 30: 6 people crossing line | Total: 22\n",
      "Frame 35: 5 people crossing line | Total: 27\n",
      "Frame 40: 2 people crossing line | Total: 29\n",
      "Frame 45: 2 people crossing line | Total: 31\n",
      "Frame 50: 3 people crossing line | Total: 34\n",
      "Frame 55: 3 people crossing line | Total: 37\n",
      "Frame 60: 5 people crossing line | Total: 42\n",
      "Frame 65: 2 people crossing line | Total: 44\n",
      "Frame 70: 2 people crossing line | Total: 46\n",
      "Frame 75: 2 people crossing line | Total: 48\n",
      "Frame 80: 3 people crossing line | Total: 51\n",
      "Frame 85: 3 people crossing line | Total: 54\n",
      "Frame 90: 2 people crossing line | Total: 56\n",
      "Frame 95: 3 people crossing line | Total: 59\n",
      "Frame 100: 2 people crossing line | Total: 61\n",
      "Frame 105: 2 people crossing line | Total: 63\n",
      "Frame 110: 3 people crossing line | Total: 66\n",
      "Frame 115: 2 people crossing line | Total: 68\n",
      "Frame 120: 5 people crossing line | Total: 73\n",
      "Frame 125: 3 people crossing line | Total: 76\n",
      "Frame 130: 2 people crossing line | Total: 78\n",
      "Frame 135: 1 people crossing line | Total: 79\n",
      "Frame 140: 1 people crossing line | Total: 80\n",
      "Frame 145: 2 people crossing line | Total: 82\n",
      "Frame 150: 5 people crossing line | Total: 87\n",
      "Frame 155: 4 people crossing line | Total: 91\n",
      "Frame 160: 7 people crossing line | Total: 98\n",
      "Frame 165: 3 people crossing line | Total: 101\n",
      "Frame 170: 7 people crossing line | Total: 108\n",
      "Frame 175: 8 people crossing line | Total: 116\n",
      "Frame 180: 6 people crossing line | Total: 122\n",
      "Frame 185: 3 people crossing line | Total: 125\n",
      "Frame 190: 3 people crossing line | Total: 128\n",
      "Frame 195: 3 people crossing line | Total: 131\n",
      "Frame 200: 5 people crossing line | Total: 136\n",
      "Frame 205: 5 people crossing line | Total: 141\n",
      "Frame 210: 2 people crossing line | Total: 143\n",
      "Frame 215: 2 people crossing line | Total: 145\n",
      "Frame 220: 2 people crossing line | Total: 147\n",
      "Frame 225: 4 people crossing line | Total: 151\n",
      "Frame 230: 5 people crossing line | Total: 156\n",
      "Frame 235: 7 people crossing line | Total: 163\n",
      "Frame 240: 6 people crossing line | Total: 169\n",
      "Frame 245: 4 people crossing line | Total: 173\n",
      "Frame 250: 4 people crossing line | Total: 177\n",
      "Frame 255: 3 people crossing line | Total: 180\n",
      "Frame 260: 4 people crossing line | Total: 184\n",
      "Frame 265: 3 people crossing line | Total: 187\n",
      "Frame 270: 5 people crossing line | Total: 192\n",
      "Frame 275: 5 people crossing line | Total: 197\n",
      "Frame 280: 4 people crossing line | Total: 201\n",
      "Frame 285: 1 people crossing line | Total: 202\n",
      "Frame 290: 3 people crossing line | Total: 205\n",
      "Frame 295: 1 people crossing line | Total: 206\n",
      "Frame 300: 2 people crossing line | Total: 208\n",
      "Frame 305: 7 people crossing line | Total: 215\n",
      "Frame 310: 4 people crossing line | Total: 219\n",
      "Frame 315: 6 people crossing line | Total: 225\n",
      "Frame 320: 5 people crossing line | Total: 230\n",
      "Frame 325: 5 people crossing line | Total: 235\n",
      "Frame 330: 4 people crossing line | Total: 239\n",
      "Frame 335: 4 people crossing line | Total: 243\n",
      "Frame 340: 5 people crossing line | Total: 248\n",
      "Frame 345: 3 people crossing line | Total: 251\n",
      "Frame 350: 4 people crossing line | Total: 255\n",
      "Frame 355: 6 people crossing line | Total: 261\n",
      "Frame 360: 4 people crossing line | Total: 265\n",
      "Frame 365: 2 people crossing line | Total: 267\n",
      "Frame 370: 3 people crossing line | Total: 270\n",
      "Frame 375: 3 people crossing line | Total: 273\n",
      "Frame 380: 3 people crossing line | Total: 276\n",
      "Frame 385: 3 people crossing line | Total: 279\n",
      "Frame 390: 4 people crossing line | Total: 283\n",
      "Frame 395: 2 people crossing line | Total: 285\n",
      "Frame 400: 3 people crossing line | Total: 288\n",
      "Frame 405: 2 people crossing line | Total: 290\n",
      "Frame 410: 4 people crossing line | Total: 294\n",
      "üõë Stopped by user\n",
      "\n",
      "üìä LINE-BASED COUNTING COMPLETE:\n",
      "   üìè Counting line position: Y = 388 (90.0% from top)\n",
      "   üéØ Total people counted crossing line: 294\n",
      "   üìπ Frames processed: 410\n",
      "   ‚è±Ô∏è Processing time: 10.1s\n",
      "   üìà Maximum crossings in single frame: 8\n",
      "   üìä Average crossings per frame: 3.59\n",
      "   üé• Video: 768x432, Line at Y=388\n",
      "\n",
      "üéâ LINE-BASED COUNTING COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class LineBasedPersonCounter:\n",
    "    def __init__(self, model_size='n', line_position_ratio=0.85):\n",
    "        \"\"\"\n",
    "        Initialize line-based person counter\n",
    "        model_size: YOLO model size ('n', 's', 'm', 'l', 'x')\n",
    "        line_position_ratio: Line position as ratio of frame height (0.0 = top, 1.0 = bottom)\n",
    "        \"\"\"\n",
    "        print(f\"üöÄ Initializing Line-Based Person Counter...\")\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_name = \"None\"\n",
    "        self.line_position_ratio = line_position_ratio\n",
    "        \n",
    "        # Counting variables\n",
    "        self.total_people_counted = 0\n",
    "        self.frame_count = 0\n",
    "        self.people_per_frame = []\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.load_model(model_size)\n",
    "        \n",
    "    def load_model(self, model_size):\n",
    "        \"\"\"Load YOLO model with error handling\"\"\"\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            model_options = [f'yolo11{model_size}.pt', f'yolov8{model_size}.pt', 'yolo11n.pt', 'yolov8n.pt']\n",
    "            \n",
    "            for model_path in model_options:\n",
    "                try:\n",
    "                    print(f\"üì• Trying to load {model_path}...\")\n",
    "                    self.model = YOLO(model_path)\n",
    "                    self.model.conf = 0.5       # Confidence threshold\n",
    "                    self.model.iou = 0.45       # IoU threshold\n",
    "                    self.model.max_det = 1000   # Max detections\n",
    "                    self.model_name = model_path\n",
    "                    print(f\"‚úÖ Successfully loaded {model_path}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to load {model_path}: {str(e)[:50]}...\")\n",
    "                    continue\n",
    "            \n",
    "            print(\"‚ùå All YOLO models failed to load\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå Ultralytics not installed. Run: pip install ultralytics\")\n",
    "    \n",
    "    def detect_people_in_frame(self, frame):\n",
    "        \"\"\"Detect people in frame and return bounding boxes\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Run YOLO detection - only detect people (class 0)\n",
    "            results = self.model(frame, classes=[0], verbose=False)\n",
    "            \n",
    "            people_boxes = []\n",
    "            \n",
    "            if results and len(results) > 0 and results[0].boxes is not None:\n",
    "                boxes = results[0].boxes\n",
    "                coords = boxes.xyxy.cpu().numpy()\n",
    "                confs = boxes.conf.cpu().numpy()\n",
    "                \n",
    "                for i in range(len(coords)):\n",
    "                    box = coords[i].astype(int)\n",
    "                    conf = float(confs[i])\n",
    "                    \n",
    "                    people_boxes.append({\n",
    "                        'box': box,  # [x1, y1, x2, y2]\n",
    "                        'confidence': conf,\n",
    "                        'center': ((box[0] + box[2]) // 2, (box[1] + box[3]) // 2),\n",
    "                        'bottom_y': box[3]  # Bottom of bounding box\n",
    "                    })\n",
    "            \n",
    "            return people_boxes\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def count_people_crossing_line(self, people_boxes, line_y):\n",
    "        \"\"\"Count people whose bounding boxes touch or cross the counting line\"\"\"\n",
    "        crossing_count = 0\n",
    "        \n",
    "        for person in people_boxes:\n",
    "            bottom_y = person['bottom_y']\n",
    "            \n",
    "            # Count if person's bottom edge touches or crosses the line\n",
    "            if bottom_y >= line_y:\n",
    "                crossing_count += 1\n",
    "        \n",
    "        return crossing_count\n",
    "    \n",
    "    def calculate_display_size(self, video_width, video_height):\n",
    "        \"\"\"Calculate display size to fit screen\"\"\"\n",
    "        max_width = 1200\n",
    "        max_height = 800\n",
    "        \n",
    "        scale_width = max_width / video_width\n",
    "        scale_height = max_height / video_height\n",
    "        scale_factor = min(scale_width, scale_height, 1.0)\n",
    "        \n",
    "        display_width = int(video_width * scale_factor)\n",
    "        display_height = int(video_height * scale_factor)\n",
    "        \n",
    "        return display_width, display_height, scale_factor\n",
    "    \n",
    "    def draw_line_and_annotations(self, frame, people_boxes, line_y, crossing_count, scale_factor=1.0):\n",
    "        \"\"\"Draw counting line, bounding boxes, and count display\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        # Scale elements for display\n",
    "        font_scale = max(0.6, scale_factor * 0.8)\n",
    "        thickness = max(2, int(scale_factor * 3))\n",
    "        \n",
    "        # Draw the GREEN COUNTING LINE (horizontal)\n",
    "        cv2.line(annotated_frame, (0, line_y), (w, line_y), (0, 255, 0), thickness + 2)\n",
    "        \n",
    "        # Add line label\n",
    "        cv2.putText(annotated_frame, 'COUNTING LINE', (w // 2 - 100, line_y - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (0, 255, 0), thickness)\n",
    "        \n",
    "        # Draw bounding boxes around detected people\n",
    "        for person in people_boxes:\n",
    "            box = person['box']\n",
    "            conf = person['confidence']\n",
    "            bottom_y = person['bottom_y']\n",
    "            \n",
    "            # Color: RED if crossing line, BLUE if not crossing\n",
    "            if bottom_y >= line_y:\n",
    "                color = (0, 0, 255)  # Red - crossing line\n",
    "                label = f\"CROSSING {conf:.2f}\"\n",
    "            else:\n",
    "                color = (255, 0, 0)  # Blue - not crossing\n",
    "                label = f\"{conf:.2f}\"\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(annotated_frame, (box[0], box[1]), (box[2], box[3]), color, thickness)\n",
    "            \n",
    "            # Draw confidence and status\n",
    "            cv2.putText(annotated_frame, label, (box[0], box[1] - 8),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.5, color, thickness - 1)\n",
    "            \n",
    "            # Draw center point\n",
    "            center = person['center']\n",
    "            cv2.circle(annotated_frame, center, max(3, int(5 * scale_factor)), color, -1)\n",
    "        \n",
    "        # LEFT CORNER: Count display with background\n",
    "        overlay = annotated_frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (400, 180), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)\n",
    "        \n",
    "        # Current frame crossing count\n",
    "        cv2.putText(annotated_frame, 'PEOPLE CROSSING LINE', (20, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)\n",
    "        cv2.putText(annotated_frame, f'This Frame: {crossing_count}', (20, 80),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 1.2, (0, 255, 255), thickness)\n",
    "        \n",
    "        # Total count for entire video\n",
    "        cv2.putText(annotated_frame, f'TOTAL COUNT: {self.total_people_counted}', (20, 130),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 1.2, (0, 255, 0), thickness + 1)\n",
    "        \n",
    "        # Statistics\n",
    "        if self.people_per_frame:\n",
    "            avg_per_frame = np.mean(self.people_per_frame)\n",
    "            cv2.putText(annotated_frame, f'Avg/Frame: {avg_per_frame:.1f}', (20, 165),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (200, 200, 200), thickness - 1)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def play_video_with_line_counting(self, video_path):\n",
    "        \"\"\"Play video with line-based people counting\"\"\"\n",
    "        \n",
    "        print(f\"üé• Opening video: {video_path}\")\n",
    "        \n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 25\n",
    "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        # Calculate counting line position\n",
    "        line_y = int(original_height * self.line_position_ratio)\n",
    "        \n",
    "        # Calculate display size\n",
    "        display_width, display_height, scale_factor = self.calculate_display_size(\n",
    "            original_width, original_height\n",
    "        )\n",
    "        \n",
    "        print(f\"üìπ Video Info: {original_width}x{original_height}, {fps} FPS, {total_frames} frames, {duration:.1f}s\")\n",
    "        print(f\"üìè Counting line at Y = {line_y} ({self.line_position_ratio * 100:.1f}% from top)\")\n",
    "        print(f\"üé¨ Starting line-based counting...\")\n",
    "        \n",
    "        # Create window\n",
    "        cv2.namedWindow('Line-Based Person Counter', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Line-Based Person Counter', display_width, display_height)\n",
    "        \n",
    "        # Reset counters\n",
    "        self.total_people_counted = 0\n",
    "        self.frame_count = 0\n",
    "        self.people_per_frame = []\n",
    "        \n",
    "        frame_number = 0\n",
    "        start_time = time.time()\n",
    "        paused = False\n",
    "        \n",
    "        print(\"Press 'q' to quit, SPACE to pause/resume, 'f' for fullscreen\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if not paused:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"üìπ Video completed!\")\n",
    "                        break\n",
    "                    \n",
    "                    frame_number += 5\n",
    "                    self.frame_count += 5\n",
    "                    \n",
    "                    # Detect people in current frame\n",
    "                    people_boxes = self.detect_people_in_frame(frame)\n",
    "                    \n",
    "                    # Count people crossing the line in this frame\n",
    "                    crossing_count = self.count_people_crossing_line(people_boxes, line_y)\n",
    "                    \n",
    "                    # Add to total count\n",
    "                    self.total_people_counted += crossing_count\n",
    "                    self.people_per_frame.append(crossing_count)\n",
    "                    \n",
    "                    # PRINT COUNT FOR EACH FRAME\n",
    "                    print(f\"Frame {frame_number}: {crossing_count} people crossing line | Total: {self.total_people_counted}\")\n",
    "                    \n",
    "                    # Draw annotations\n",
    "                    display_frame = self.draw_line_and_annotations(\n",
    "                        frame, people_boxes, line_y, crossing_count, scale_factor\n",
    "                    )\n",
    "                    \n",
    "                    # Add progress info\n",
    "                    progress = (frame_number / total_frames) * 100\n",
    "                    timestamp = frame_number / fps\n",
    "                    cv2.putText(display_frame, f'Progress: {progress:.1f}% | Time: {timestamp:.1f}s', \n",
    "                               (original_width - int(300 * scale_factor), original_height - int(30 * scale_factor)),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, scale_factor * 0.6, (255, 255, 255), max(1, int(scale_factor * 2)))\n",
    "                    \n",
    "                    # Resize for display\n",
    "                    resized_frame = cv2.resize(display_frame, (display_width, display_height))\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Line-Based Person Counter', resized_frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(max(1, int(1000/fps))) & 0xFF\n",
    "                \n",
    "                if key == ord('q') or key == 27:  # 'q' or ESC\n",
    "                    print(\"üõë Stopped by user\")\n",
    "                    break\n",
    "                elif key == ord(' '):  # SPACE to pause/resume\n",
    "                    paused = not paused\n",
    "                    print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "                elif key == ord('f'):  # 'f' for fullscreen\n",
    "                    cv2.setWindowProperty('Line-Based Person Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "                elif key == ord('n'):  # 'n' for normal\n",
    "                    cv2.setWindowProperty('Line-Based Person Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "                elif key == ord('s'):  # 's' to save screenshot\n",
    "                    screenshot_name = f\"line_counter_frame_{frame_number}.jpg\"\n",
    "                    cv2.imwrite(screenshot_name, resized_frame)\n",
    "                    print(f\"üì∏ Screenshot saved: {screenshot_name}\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Playback interrupted by user (Ctrl+C)\")\n",
    "        \n",
    "        finally:\n",
    "            # Cleanup\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            # Final statistics\n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\nüìä LINE-BASED COUNTING COMPLETE:\")\n",
    "            print(f\"   üìè Counting line position: Y = {line_y} ({self.line_position_ratio * 100:.1f}% from top)\")\n",
    "            print(f\"   üéØ Total people counted crossing line: {self.total_people_counted}\")\n",
    "            print(f\"   üìπ Frames processed: {self.frame_count}\")\n",
    "            print(f\"   ‚è±Ô∏è Processing time: {total_time:.1f}s\")\n",
    "            if self.people_per_frame:\n",
    "                print(f\"   üìà Maximum crossings in single frame: {max(self.people_per_frame)}\")\n",
    "                print(f\"   üìä Average crossings per frame: {np.mean(self.people_per_frame):.2f}\")\n",
    "            print(f\"   üé• Video: {original_width}x{original_height}, Line at Y={line_y}\")\n",
    "\n",
    "# Initialize and use the line-based counter\n",
    "print(\"üöÄ INITIALIZING LINE-BASED PERSON COUNTER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Create line-based counter\n",
    "    counter = LineBasedPersonCounter('n', line_position_ratio=0.90)  # Line at 85% from top\n",
    "    \n",
    "    print(\"\\n‚úÖ INITIALIZATION SUCCESSFUL!\")\n",
    "    print(f\"üì± Model: {counter.model_name}\")\n",
    "    print(f\"üìè Line position: {counter.line_position_ratio * 100:.1f}% from top\")\n",
    "    \n",
    "    print(f\"\\nüéØ READY FOR LINE-BASED COUNTING!\")\n",
    "    print(f\"\\nüé¨ CONTROLS:\")\n",
    "    print(f\"   'q' or ESC = Quit\")\n",
    "    print(f\"   SPACE = Pause/Resume\")\n",
    "    print(f\"   'f' = Fullscreen\")\n",
    "    print(f\"   'n' = Normal window\")\n",
    "    print(f\"   's' = Save screenshot\")\n",
    "    \n",
    "    print(f\"\\nüìè HOW IT WORKS:\")\n",
    "    print(f\"   ‚Ä¢ Green horizontal line appears at {counter.line_position_ratio * 100:.1f}% from top\")\n",
    "    print(f\"   ‚Ä¢ People are counted ONLY when they touch/cross this line\")\n",
    "    print(f\"   ‚Ä¢ Red boxes = people crossing line, Blue boxes = people not crossing\")\n",
    "    print(f\"   ‚Ä¢ Total count accumulates for entire video\")\n",
    "    \n",
    "    # Play your video with line-based counting\n",
    "    counter.play_video_with_line_counting('testing10.mp4')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ LINE-BASED COUNTING COMPLETE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144fe94a-3e14-4c4d-9645-1e77ba9859b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING DIRECTIONAL PERSON COUNTER\n",
      "=================================================================\n",
      "üöÄ Initializing Directional Person Counter...\n",
      "üì• Trying to load yolo11n.pt...\n",
      "‚úÖ Successfully loaded yolo11n.pt\n",
      "\n",
      "‚úÖ INITIALIZATION SUCCESSFUL!\n",
      "üì± Model: yolo11n.pt\n",
      "üìè Line position: 90.0% from top\n",
      "\n",
      "üéØ DIRECTIONAL COUNTING FEATURES:\n",
      "   ‚úÖ Only counts people moving bottom‚Üítop (entering)\n",
      "   ‚ùå Subtracts count for people moving top‚Üíbottom (exiting)\n",
      "   üö´ Ignores stationary people\n",
      "   üîç Tracks individual people across frames\n",
      "   üìä Shows net occupancy count\n",
      "\n",
      "üé¨ CONTROLS:\n",
      "   'q' or ESC = Quit\n",
      "   SPACE = Pause/Resume\n",
      "   'f' = Fullscreen\n",
      "   'n' = Normal window\n",
      "\n",
      "üé® VISUAL INDICATORS:\n",
      "   üü¢ Green circles = People moving up (entering)\n",
      "   üî¥ Red circles = People moving down (exiting)\n",
      "   ‚ö´ Gray circles = Stationary people (ignored)\n",
      "   üîç Trails show movement paths\n",
      "üé• Opening video: testing10.mp4\n",
      "üìπ Video: 768x432, 25 FPS, 750 frames\n",
      "üìè Counting line at Y = 388 (90.0% from top)\n",
      "üéØ Direction: Only counting bottom‚Üítop (entering), subtracting top‚Üíbottom (exiting)\n",
      "üé¨ Controls: 'q'=quit, SPACE=pause/resume, 'f'=fullscreen\n",
      "‚ùå Person 7 EXITED (top‚Üíbottom) | Total: -1\n",
      "‚ùå Person 17 EXITED (top‚Üíbottom) | Total: -2\n",
      "‚úÖ Person 2 ENTERED (bottom‚Üítop) | Total: -1\n",
      "‚úÖ Person 16 ENTERED (bottom‚Üítop) | Total: 0\n",
      "‚ùå Person 3 EXITED (top‚Üíbottom) | Total: -1\n",
      "‚úÖ Person 7 ENTERED (bottom‚Üítop) | Total: 0\n",
      "‚ùå Person 16 EXITED (top‚Üíbottom) | Total: -1\n",
      "‚úÖ Person 35 ENTERED (bottom‚Üítop) | Total: 0\n",
      "‚ùå Person 38 EXITED (top‚Üíbottom) | Total: -1\n",
      "‚úÖ Person 7 ENTERED (bottom‚Üítop) | Total: 0\n",
      "‚ùå Person 35 EXITED (top‚Üíbottom) | Total: -1\n",
      "‚ùå Person 38 EXITED (top‚Üíbottom) | Total: -2\n",
      "‚úÖ Person 35 ENTERED (bottom‚Üítop) | Total: -1\n",
      "‚ùå Person 17 EXITED (top‚Üíbottom) | Total: -2\n",
      "‚úÖ Person 35 ENTERED (bottom‚Üítop) | Total: -1\n",
      "‚úÖ Person 36 ENTERED (bottom‚Üítop) | Total: 0\n",
      "‚úÖ Person 38 ENTERED (bottom‚Üítop) | Total: 1\n",
      "‚ùå Person 44 EXITED (top‚Üíbottom) | Total: 0\n",
      "‚úÖ Person 16 ENTERED (bottom‚Üítop) | Total: 1\n",
      "‚ùå Person 16 EXITED (top‚Üíbottom) | Total: 0\n",
      "‚úÖ Person 3 ENTERED (bottom‚Üítop) | Total: 1\n",
      "‚úÖ Person 47 ENTERED (bottom‚Üítop) | Total: 2\n",
      "‚ùå Person 47 EXITED (top‚Üíbottom) | Total: 1\n",
      "‚úÖ Person 47 ENTERED (bottom‚Üítop) | Total: 2\n",
      "‚ùå Person 47 EXITED (top‚Üíbottom) | Total: 1\n",
      "‚úÖ Person 47 ENTERED (bottom‚Üítop) | Total: 2\n",
      "‚úÖ Person 16 ENTERED (bottom‚Üítop) | Total: 3\n",
      "‚úÖ Person 23 ENTERED (bottom‚Üítop) | Total: 4\n",
      "‚ùå Person 35 EXITED (top‚Üíbottom) | Total: 3\n",
      "‚ùå Person 16 EXITED (top‚Üíbottom) | Total: 2\n",
      "‚úÖ Person 16 ENTERED (bottom‚Üítop) | Total: 3\n",
      "‚úÖ Person 64 ENTERED (bottom‚Üítop) | Total: 4\n",
      "‚úÖ Person 38 ENTERED (bottom‚Üítop) | Total: 5\n",
      "‚úÖ Person 44 ENTERED (bottom‚Üítop) | Total: 6\n",
      "‚ùå Person 47 EXITED (top‚Üíbottom) | Total: 5\n",
      "‚úÖ Person 23 ENTERED (bottom‚Üítop) | Total: 6\n",
      "‚úÖ Person 58 ENTERED (bottom‚Üítop) | Total: 7\n",
      "‚úÖ Person 38 ENTERED (bottom‚Üítop) | Total: 8\n",
      "‚ùå Person 7 EXITED (top‚Üíbottom) | Total: 7\n",
      "‚úÖ Person 44 ENTERED (bottom‚Üítop) | Total: 8\n",
      "üõë Stopped by user\n",
      "\n",
      "üìä DIRECTIONAL COUNTING COMPLETE:\n",
      "   üìè Line position: Y = 388 (90.0% from top)\n",
      "   üéØ NET COUNT (current occupancy): 8\n",
      "   ‚¨ÜÔ∏è Total entered (bottom‚Üítop): 24\n",
      "   ‚¨áÔ∏è Total exited (top‚Üíbottom): 16\n",
      "   üìπ Frames processed: 119\n",
      "   ‚è±Ô∏è Processing time: 15.3s\n",
      "   üé• Video: 768x432\n",
      "\n",
      "üéâ DIRECTIONAL COUNTING READY!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from scipy.spatial import distance as dist\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=30, maxDistance=80):\n",
    "        \"\"\"Simple centroid tracker for person movement tracking\"\"\"\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        self.maxDistance = maxDistance\n",
    "        \n",
    "        # For direction tracking\n",
    "        self.centroid_history = OrderedDict()  # Store recent positions\n",
    "        self.max_history_length = 10\n",
    "\n",
    "    def register(self, centroid):\n",
    "        \"\"\"Register new tracked object\"\"\"\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.centroid_history[self.nextObjectID] = [centroid]\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        \"\"\"Remove tracked object\"\"\"\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.centroid_history[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        if len(rects) == 0:\n",
    "            # Mark all existing objects as disappeared\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "\n",
    "        # Initialize centroids for current frame\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        # If no existing objects, register all as new\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        else:\n",
    "            # Match existing objects to new detections\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # Compute distance matrix\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "            \n",
    "            # Find minimum distances\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # Update matched objects\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # Update centroid history\n",
    "                self.centroid_history[objectID].append(tuple(inputCentroids[col]))\n",
    "                if len(self.centroid_history[objectID]) > self.max_history_length:\n",
    "                    self.centroid_history[objectID].pop(0)\n",
    "\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # Handle unmatched objects and detections\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # Mark unmatched objects as disappeared\n",
    "            for row in unusedRows:\n",
    "                objectID = objectIDs[row]\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # Register new objects\n",
    "            for col in unusedCols:\n",
    "                self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "class DirectionalPersonCounter:\n",
    "    def __init__(self, model_size='n', line_position_ratio=0.85):\n",
    "        \"\"\"\n",
    "        Direction-aware person counter with tracking\n",
    "        Only counts people moving from bottom to top, ignores stationary people\n",
    "        \"\"\"\n",
    "        print(f\"üöÄ Initializing Directional Person Counter...\")\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_name = \"None\"\n",
    "        self.line_position_ratio = line_position_ratio\n",
    "        \n",
    "        # Initialize tracker\n",
    "        self.tracker = CentroidTracker(maxDisappeared=30, maxDistance=100)\n",
    "        \n",
    "        # Counting variables\n",
    "        self.total_people_counted = 0  # Net count (up - down)\n",
    "        self.people_entered = 0        # Bottom to top crossings\n",
    "        self.people_exited = 0         # Top to bottom crossings\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # Track line crossings\n",
    "        self.line_crossed_objects = {}  # objectID: {'crossed': bool, 'direction': str, 'position': str}\n",
    "        self.movement_threshold = 5     # Minimum pixels to consider as movement\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.load_model(model_size)\n",
    "        \n",
    "    def load_model(self, model_size):\n",
    "        \"\"\"Load YOLO model with error handling\"\"\"\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            model_options = [f'yolo11{model_size}.pt', f'yolov8{model_size}.pt', 'yolo11n.pt', 'yolov8n.pt']\n",
    "            \n",
    "            for model_path in model_options:\n",
    "                try:\n",
    "                    print(f\"üì• Trying to load {model_path}...\")\n",
    "                    self.model = YOLO(model_path)\n",
    "                    self.model.conf = 0.5\n",
    "                    self.model.iou = 0.45\n",
    "                    self.model.max_det = 1000\n",
    "                    self.model_name = model_path\n",
    "                    print(f\"‚úÖ Successfully loaded {model_path}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            print(\"‚ùå All YOLO models failed to load\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå Ultralytics not installed\")\n",
    "    \n",
    "    def detect_people_in_frame(self, frame):\n",
    "        \"\"\"Detect people and return bounding boxes\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = self.model(frame, classes=[0], verbose=False)\n",
    "            people_boxes = []\n",
    "            \n",
    "            if results and len(results) > 0 and results[0].boxes is not None:\n",
    "                boxes = results[0].boxes\n",
    "                coords = boxes.xyxy.cpu().numpy()\n",
    "                confs = boxes.conf.cpu().numpy()\n",
    "                \n",
    "                for i in range(len(coords)):\n",
    "                    box = coords[i].astype(int)\n",
    "                    conf = float(confs[i])\n",
    "                    \n",
    "                    people_boxes.append([box[0], box[1], box[2], box[3]])  # [x1, y1, x2, y2]\n",
    "            \n",
    "            return people_boxes\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def calculate_movement_direction(self, objectID, line_y):\n",
    "        \"\"\"Calculate movement direction for tracked object\"\"\"\n",
    "        if objectID not in self.tracker.centroid_history:\n",
    "            return None, False\n",
    "        \n",
    "        history = self.tracker.centroid_history[objectID]\n",
    "        if len(history) < 3:  # Need at least 3 points for reliable direction\n",
    "            return None, False\n",
    "        \n",
    "        # Get recent positions\n",
    "        recent_positions = history[-5:]  # Last 5 positions\n",
    "        \n",
    "        # Calculate overall vertical movement\n",
    "        start_y = recent_positions[0][1]\n",
    "        end_y = recent_positions[-1][1]\n",
    "        vertical_movement = end_y - start_y\n",
    "        \n",
    "        # Check if movement is significant (not stationary)\n",
    "        if abs(vertical_movement) < self.movement_threshold:\n",
    "            return \"stationary\", False\n",
    "        \n",
    "        # Determine direction\n",
    "        if vertical_movement > 0:\n",
    "            return \"top_to_bottom\", True  # Moving down\n",
    "        else:\n",
    "            return \"bottom_to_top\", True  # Moving up\n",
    "    \n",
    "    def check_line_crossings(self, objects, line_y):\n",
    "        \"\"\"Check for line crossings and update counts\"\"\"\n",
    "        crossings_this_frame = []\n",
    "        \n",
    "        for objectID, centroid in objects.items():\n",
    "            current_y = centroid[1]\n",
    "            \n",
    "            # Initialize tracking for new objects\n",
    "            if objectID not in self.line_crossed_objects:\n",
    "                position = \"below\" if current_y > line_y else \"above\"\n",
    "                self.line_crossed_objects[objectID] = {\n",
    "                    'crossed': False,\n",
    "                    'last_position': position,\n",
    "                    'current_position': position\n",
    "                }\n",
    "            \n",
    "            # Update current position\n",
    "            current_position = \"below\" if current_y > line_y else \"above\"\n",
    "            last_position = self.line_crossed_objects[objectID]['last_position']\n",
    "            \n",
    "            # Check for line crossing\n",
    "            if last_position != current_position:\n",
    "                direction, is_moving = self.calculate_movement_direction(objectID, line_y)\n",
    "                \n",
    "                if is_moving and direction != \"stationary\":\n",
    "                    if last_position == \"below\" and current_position == \"above\":\n",
    "                        # Person moved from bottom to top (ENTERING)\n",
    "                        if direction == \"bottom_to_top\":\n",
    "                            self.people_entered += 1\n",
    "                            self.total_people_counted += 1\n",
    "                            crossings_this_frame.append({\n",
    "                                'objectID': objectID,\n",
    "                                'direction': 'ENTERING',\n",
    "                                'type': 'bottom_to_top',\n",
    "                                'centroid': centroid\n",
    "                            })\n",
    "                            print(f\"‚úÖ Person {objectID} ENTERED (bottom‚Üítop) | Total: {self.total_people_counted}\")\n",
    "                    \n",
    "                    elif last_position == \"above\" and current_position == \"below\":\n",
    "                        # Person moved from top to bottom (EXITING)\n",
    "                        if direction == \"top_to_bottom\":\n",
    "                            self.people_exited += 1\n",
    "                            self.total_people_counted -= 1\n",
    "                            crossings_this_frame.append({\n",
    "                                'objectID': objectID,\n",
    "                                'direction': 'EXITING',\n",
    "                                'type': 'top_to_bottom',\n",
    "                                'centroid': centroid\n",
    "                            })\n",
    "                            print(f\"‚ùå Person {objectID} EXITED (top‚Üíbottom) | Total: {self.total_people_counted}\")\n",
    "            \n",
    "            # Update position tracking\n",
    "            self.line_crossed_objects[objectID]['last_position'] = current_position\n",
    "            self.line_crossed_objects[objectID]['current_position'] = current_position\n",
    "        \n",
    "        # Clean up tracking for disappeared objects\n",
    "        current_object_ids = set(objects.keys())\n",
    "        to_remove = []\n",
    "        for objectID in self.line_crossed_objects.keys():\n",
    "            if objectID not in current_object_ids:\n",
    "                to_remove.append(objectID)\n",
    "        \n",
    "        for objectID in to_remove:\n",
    "            del self.line_crossed_objects[objectID]\n",
    "        \n",
    "        return crossings_this_frame\n",
    "    \n",
    "    def calculate_display_size(self, video_width, video_height):\n",
    "        \"\"\"Calculate display size to fit screen\"\"\"\n",
    "        max_width = 1200\n",
    "        max_height = 800\n",
    "        \n",
    "        scale_width = max_width / video_width\n",
    "        scale_height = max_height / video_height\n",
    "        scale_factor = min(scale_width, scale_height, 1.0)\n",
    "        \n",
    "        display_width = int(video_width * scale_factor)\n",
    "        display_height = int(video_height * scale_factor)\n",
    "        \n",
    "        return display_width, display_height, scale_factor\n",
    "    \n",
    "    def draw_tracking_and_counting(self, frame, objects, line_y, crossings, scale_factor=1.0):\n",
    "        \"\"\"Draw tracking, line, and counting information\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        font_scale = max(0.6, scale_factor * 0.8)\n",
    "        thickness = max(2, int(scale_factor * 3))\n",
    "        \n",
    "        # Draw the GREEN COUNTING LINE\n",
    "        cv2.line(annotated_frame, (0, line_y), (w, line_y), (0, 255, 0), thickness + 2)\n",
    "        cv2.putText(annotated_frame, 'DIRECTIONAL COUNTING LINE', (w // 2 - 150, line_y - 15),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (0, 255, 0), thickness)\n",
    "        \n",
    "        # Draw tracked objects with direction info\n",
    "        for objectID, centroid in objects.items():\n",
    "            direction, is_moving = self.calculate_movement_direction(objectID, line_y)\n",
    "            \n",
    "            # Color coding based on movement and position\n",
    "            if direction == \"stationary\":\n",
    "                color = (128, 128, 128)  # Gray for stationary\n",
    "                status = \"STATIONARY\"\n",
    "            elif direction == \"bottom_to_top\":\n",
    "                color = (0, 255, 0)      # Green for upward movement\n",
    "                status = \"MOVING UP\"\n",
    "            elif direction == \"top_to_bottom\":\n",
    "                color = (0, 0, 255)      # Red for downward movement\n",
    "                status = \"MOVING DOWN\"\n",
    "            else:\n",
    "                color = (255, 255, 255)  # White for unknown\n",
    "                status = \"TRACKING\"\n",
    "            \n",
    "            # Draw tracking circle\n",
    "            cv2.circle(annotated_frame, centroid, 8, color, -1)\n",
    "            cv2.circle(annotated_frame, centroid, 12, color, 2)\n",
    "            \n",
    "            # Draw object ID and status\n",
    "            cv2.putText(annotated_frame, f\"ID:{objectID}\", \n",
    "                       (centroid[0] - 20, centroid[1] - 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.5, color, thickness - 1)\n",
    "            cv2.putText(annotated_frame, status, \n",
    "                       (centroid[0] - 30, centroid[1] + 25),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.4, color, thickness - 1)\n",
    "            \n",
    "            # Draw movement trail\n",
    "            if objectID in self.tracker.centroid_history:\n",
    "                history = self.tracker.centroid_history[objectID]\n",
    "                if len(history) > 1:\n",
    "                    for i in range(1, len(history)):\n",
    "                        cv2.line(annotated_frame, history[i-1], history[i], color, 2)\n",
    "        \n",
    "        # Highlight recent crossings\n",
    "        for crossing in crossings:\n",
    "            centroid = crossing['centroid']\n",
    "            if crossing['direction'] == 'ENTERING':\n",
    "                cv2.circle(annotated_frame, centroid, 20, (0, 255, 0), 3)\n",
    "                cv2.putText(annotated_frame, \"ENTERED!\", (centroid[0] - 30, centroid[1] - 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.6, (0, 255, 0), thickness)\n",
    "            else:\n",
    "                cv2.circle(annotated_frame, centroid, 20, (0, 0, 255), 3)\n",
    "                cv2.putText(annotated_frame, \"EXITED!\", (centroid[0] - 25, centroid[1] - 30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.6, (0, 0, 255), thickness)\n",
    "        \n",
    "        # LEFT CORNER: Counting display\n",
    "        overlay = annotated_frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (450, 220), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.8, annotated_frame, 0.2, 0, annotated_frame)\n",
    "        \n",
    "        # Count information\n",
    "        cv2.putText(annotated_frame, 'DIRECTIONAL COUNTER', (20, 35),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.9, (255, 255, 255), thickness)\n",
    "        \n",
    "        cv2.putText(annotated_frame, f'NET COUNT: {self.total_people_counted}', (20, 70),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 1.2, (0, 255, 0), thickness + 1)\n",
    "        \n",
    "        cv2.putText(annotated_frame, f'Entered (‚Üë): {self.people_entered}', (20, 105),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.8, (0, 255, 0), thickness)\n",
    "        cv2.putText(annotated_frame, f'Exited (‚Üì): {self.people_exited}', (20, 135),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.8, (0, 0, 255), thickness)\n",
    "        \n",
    "        cv2.putText(annotated_frame, f'Active Tracks: {len(objects)}', (20, 165),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (255, 255, 0), thickness - 1)\n",
    "        \n",
    "        # Legend\n",
    "        cv2.putText(annotated_frame, 'Green=Up, Red=Down, Gray=Still', (20, 195),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.6, (200, 200, 200), thickness - 1)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def play_video_with_directional_counting(self, video_path):\n",
    "        \"\"\"Play video with directional people counting\"\"\"\n",
    "        \n",
    "        print(f\"üé• Opening video: {video_path}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 25\n",
    "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        line_y = int(original_height * self.line_position_ratio)\n",
    "        display_width, display_height, scale_factor = self.calculate_display_size(\n",
    "            original_width, original_height\n",
    "        )\n",
    "        \n",
    "        print(f\"üìπ Video: {original_width}x{original_height}, {fps} FPS, {total_frames} frames\")\n",
    "        print(f\"üìè Counting line at Y = {line_y} ({self.line_position_ratio * 100:.1f}% from top)\")\n",
    "        print(f\"üéØ Direction: Only counting bottom‚Üítop (entering), subtracting top‚Üíbottom (exiting)\")\n",
    "        \n",
    "        cv2.namedWindow('Directional Person Counter', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Directional Person Counter', display_width, display_height)\n",
    "        \n",
    "        frame_number = 0\n",
    "        start_time = time.time()\n",
    "        paused = False\n",
    "        \n",
    "        print(\"üé¨ Controls: 'q'=quit, SPACE=pause/resume, 'f'=fullscreen\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if not paused:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"üìπ Video completed!\")\n",
    "                        break\n",
    "                    \n",
    "                    frame_number += 1\n",
    "                    self.frame_count += 1\n",
    "                    \n",
    "                    # Detect people\n",
    "                    people_boxes = self.detect_people_in_frame(frame)\n",
    "                    \n",
    "                    # Update tracker\n",
    "                    objects = self.tracker.update(people_boxes)\n",
    "                    \n",
    "                    # Check for line crossings and update counts\n",
    "                    crossings = self.check_line_crossings(objects, line_y)\n",
    "                    \n",
    "                    # Draw everything\n",
    "                    display_frame = self.draw_tracking_and_counting(\n",
    "                        frame, objects, line_y, crossings, scale_factor\n",
    "                    )\n",
    "                    \n",
    "                    # Add progress info\n",
    "                    progress = (frame_number / total_frames) * 100\n",
    "                    timestamp = frame_number / fps\n",
    "                    cv2.putText(display_frame, f'Progress: {progress:.1f}% | Time: {timestamp:.1f}s', \n",
    "                               (original_width - int(300 * scale_factor), original_height - int(30 * scale_factor)),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, scale_factor * 0.6, (255, 255, 255), max(1, int(scale_factor * 2)))\n",
    "                    \n",
    "                    resized_frame = cv2.resize(display_frame, (display_width, display_height))\n",
    "                \n",
    "                cv2.imshow('Directional Person Counter', resized_frame)\n",
    "                \n",
    "                key = cv2.waitKey(max(1, int(1000/fps))) & 0xFF\n",
    "                \n",
    "                if key == ord('q') or key == 27:\n",
    "                    print(\"üõë Stopped by user\")\n",
    "                    break\n",
    "                elif key == ord(' '):\n",
    "                    paused = not paused\n",
    "                    print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "                elif key == ord('f'):\n",
    "                    cv2.setWindowProperty('Directional Person Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "                elif key == ord('n'):\n",
    "                    cv2.setWindowProperty('Directional Person Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Interrupted by user\")\n",
    "        \n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\nüìä DIRECTIONAL COUNTING COMPLETE:\")\n",
    "            print(f\"   üìè Line position: Y = {line_y} ({self.line_position_ratio * 100:.1f}% from top)\")\n",
    "            print(f\"   üéØ NET COUNT (current occupancy): {self.total_people_counted}\")\n",
    "            print(f\"   ‚¨ÜÔ∏è Total entered (bottom‚Üítop): {self.people_entered}\")\n",
    "            print(f\"   ‚¨áÔ∏è Total exited (top‚Üíbottom): {self.people_exited}\")\n",
    "            print(f\"   üìπ Frames processed: {self.frame_count}\")\n",
    "            print(f\"   ‚è±Ô∏è Processing time: {processing_time:.1f}s\")\n",
    "            print(f\"   üé• Video: {original_width}x{original_height}\")\n",
    "\n",
    "# Install required package first (run once)\n",
    "# pip install scipy\n",
    "\n",
    "# Initialize and use the directional counter\n",
    "print(\"üöÄ INITIALIZING DIRECTIONAL PERSON COUNTER\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "try:\n",
    "    # Create directional counter\n",
    "    counter = DirectionalPersonCounter('n', line_position_ratio=0.90)\n",
    "    \n",
    "    print(\"\\n‚úÖ INITIALIZATION SUCCESSFUL!\")\n",
    "    print(f\"üì± Model: {counter.model_name}\")\n",
    "    print(f\"üìè Line position: {counter.line_position_ratio * 100:.1f}% from top\")\n",
    "    \n",
    "    print(f\"\\nüéØ DIRECTIONAL COUNTING FEATURES:\")\n",
    "    print(f\"   ‚úÖ Only counts people moving bottom‚Üítop (entering)\")\n",
    "    print(f\"   ‚ùå Subtracts count for people moving top‚Üíbottom (exiting)\")\n",
    "    print(f\"   üö´ Ignores stationary people\")\n",
    "    print(f\"   üîç Tracks individual people across frames\")\n",
    "    print(f\"   üìä Shows net occupancy count\")\n",
    "    \n",
    "    print(f\"\\nüé¨ CONTROLS:\")\n",
    "    print(f\"   'q' or ESC = Quit\")\n",
    "    print(f\"   SPACE = Pause/Resume\")\n",
    "    print(f\"   'f' = Fullscreen\")\n",
    "    print(f\"   'n' = Normal window\")\n",
    "    \n",
    "    print(f\"\\nüé® VISUAL INDICATORS:\")\n",
    "    print(f\"   üü¢ Green circles = People moving up (entering)\")\n",
    "    print(f\"   üî¥ Red circles = People moving down (exiting)\")\n",
    "    print(f\"   ‚ö´ Gray circles = Stationary people (ignored)\")\n",
    "    print(f\"   üîç Trails show movement paths\")\n",
    "    \n",
    "    # Run with your video\n",
    "    counter.play_video_with_directional_counting('testing10.mp4')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° REQUIREMENTS:\")\n",
    "    print(\"   pip install ultralytics opencv-python scipy\")\n",
    "\n",
    "print(\"\\nüéâ DIRECTIONAL COUNTING READY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fb258b-6671-4632-a6c5-8e58c090a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ INITIALIZING ENTERING-ONLY PERSON COUNTER\n",
      "======================================================================\n",
      "üöÄ Initializing ENTERING-ONLY Person Counter...\n",
      "üì• Trying to load yolo11n.pt...\n",
      "‚úÖ Successfully loaded yolo11n.pt\n",
      "\n",
      "‚úÖ INITIALIZATION SUCCESSFUL!\n",
      "üì± Model: yolo11n.pt\n",
      "üìè Entry line position: 90.0% from top\n",
      "\n",
      "üéØ ENTERING-ONLY FEATURES:\n",
      "   ‚úÖ Only tracks people moving bottom‚Üítop (entering)\n",
      "   üö´ Completely ignores people moving top‚Üíbottom (exiting)\n",
      "   üö´ Completely ignores stationary people\n",
      "   üîç Only displays entering people with trails\n",
      "   üìä Shows only total entered count (no subtraction)\n",
      "\n",
      "üé¨ CONTROLS:\n",
      "   'q' or ESC = Quit\n",
      "   SPACE = Pause/Resume\n",
      "   'f' = Fullscreen\n",
      "   'n' = Normal window\n",
      "\n",
      "üé® VISUAL INDICATORS (ENTERING PEOPLE ONLY):\n",
      "   üü° Yellow circles = Just entered through line\n",
      "   üü¢ Green circles = Previously entered people\n",
      "   üü† Orange circles = Approaching entry line\n",
      "   üîç Colored trails = Movement paths of entering people\n",
      "üé• Opening video: testing9.mp4\n",
      "üìπ Video: 768x432, 30 FPS, 169 frames\n",
      "üìè Entry line at Y = 388 (90.0% from top)\n",
      "üéØ Mode: ENTERING PEOPLE ONLY (bottom‚Üítop)\n",
      "üö´ Ignoring: Exiting people (top‚Üíbottom) and stationary people\n",
      "üé¨ Controls: 'q'=quit, SPACE=pause/resume, 'f'=fullscreen\n",
      "Frame 4: 3 entering people tracked | Total entered: 0\n",
      "‚úÖ Person 0 ENTERED! Total entered: 1\n",
      "Frame 5: 5 entering people tracked | Total entered: 1\n",
      "‚úÖ Person 3 ENTERED! Total entered: 2\n",
      "Frame 6: 6 entering people tracked | Total entered: 2\n",
      "Frame 7: 5 entering people tracked | Total entered: 2\n",
      "Frame 8: 4 entering people tracked | Total entered: 2\n",
      "Frame 9: 5 entering people tracked | Total entered: 2\n",
      "Frame 10: 5 entering people tracked | Total entered: 2\n",
      "Frame 11: 5 entering people tracked | Total entered: 2\n",
      "Frame 12: 4 entering people tracked | Total entered: 2\n",
      "Frame 13: 5 entering people tracked | Total entered: 2\n",
      "Frame 14: 5 entering people tracked | Total entered: 2\n",
      "Frame 15: 6 entering people tracked | Total entered: 2\n",
      "Frame 16: 5 entering people tracked | Total entered: 2\n",
      "Frame 17: 5 entering people tracked | Total entered: 2\n",
      "Frame 18: 4 entering people tracked | Total entered: 2\n",
      "Frame 19: 4 entering people tracked | Total entered: 2\n",
      "Frame 20: 4 entering people tracked | Total entered: 2\n",
      "Frame 21: 4 entering people tracked | Total entered: 2\n",
      "Frame 22: 4 entering people tracked | Total entered: 2\n",
      "Frame 23: 4 entering people tracked | Total entered: 2\n",
      "‚úÖ Person 17 ENTERED! Total entered: 3\n",
      "Frame 24: 5 entering people tracked | Total entered: 3\n",
      "Frame 25: 4 entering people tracked | Total entered: 3\n",
      "Frame 26: 4 entering people tracked | Total entered: 3\n",
      "Frame 27: 4 entering people tracked | Total entered: 3\n",
      "Frame 28: 5 entering people tracked | Total entered: 3\n",
      "Frame 29: 5 entering people tracked | Total entered: 3\n",
      "Frame 30: 5 entering people tracked | Total entered: 3\n",
      "Frame 31: 6 entering people tracked | Total entered: 3\n",
      "Frame 32: 6 entering people tracked | Total entered: 3\n",
      "Frame 33: 5 entering people tracked | Total entered: 3\n",
      "Frame 34: 5 entering people tracked | Total entered: 3\n",
      "üõë Stopped by user\n",
      "\n",
      "üìä ENTERING-ONLY COUNTING COMPLETE:\n",
      "   üìè Entry line position: Y = 388 (90.0% from top)\n",
      "   ‚úÖ TOTAL PEOPLE ENTERED: 3\n",
      "   üìπ Frames processed: 34\n",
      "   ‚è±Ô∏è Processing time: 4.8s\n",
      "   üéØ Mode: ENTERING ONLY (ignored exiting & stationary people)\n",
      "\n",
      "üéâ ENTERING-ONLY COUNTING READY!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from scipy.spatial import distance as dist\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=30, maxDistance=80):\n",
    "        \"\"\"Simple centroid tracker for person movement tracking\"\"\"\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "        self.maxDistance = maxDistance\n",
    "        \n",
    "        # For direction tracking\n",
    "        self.centroid_history = OrderedDict()\n",
    "        self.max_history_length = 8\n",
    "\n",
    "    def register(self, centroid):\n",
    "        \"\"\"Register new tracked object\"\"\"\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.centroid_history[self.nextObjectID] = [centroid]\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        \"\"\"Remove tracked object\"\"\"\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.centroid_history[objectID]\n",
    "\n",
    "    def update(self, rects):\n",
    "        \"\"\"Update tracker with new detections\"\"\"\n",
    "        if len(rects) == 0:\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "            return self.objects\n",
    "\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(len(inputCentroids)):\n",
    "                self.register(inputCentroids[i])\n",
    "        else:\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "            rows = D.min(axis=1).argsort()\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # Update centroid history\n",
    "                self.centroid_history[objectID].append(tuple(inputCentroids[col]))\n",
    "                if len(self.centroid_history[objectID]) > self.max_history_length:\n",
    "                    self.centroid_history[objectID].pop(0)\n",
    "\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # Handle unmatched objects and detections\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            for row in unusedRows:\n",
    "                objectID = objectIDs[row]\n",
    "                self.disappeared[objectID] += 1\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            for col in unusedCols:\n",
    "                self.register(inputCentroids[col])\n",
    "\n",
    "        return self.objects\n",
    "\n",
    "class EnteringOnlyPersonCounter:\n",
    "    def __init__(self, model_size='n', line_position_ratio=0.85):\n",
    "        \"\"\"\n",
    "        Person counter that ONLY tracks and displays people entering (bottom‚Üítop)\n",
    "        Completely ignores exiting and stationary people\n",
    "        \"\"\"\n",
    "        print(f\"üöÄ Initializing ENTERING-ONLY Person Counter...\")\n",
    "        \n",
    "        self.model = None\n",
    "        self.model_name = \"None\"\n",
    "        self.line_position_ratio = line_position_ratio\n",
    "        \n",
    "        # Initialize tracker\n",
    "        self.tracker = CentroidTracker(maxDisappeared=25, maxDistance=100)\n",
    "        \n",
    "        # Counting variables - ONLY for entering people\n",
    "        self.total_entered_count = 0\n",
    "        self.frame_count = 0\n",
    "        \n",
    "        # Track only entering people\n",
    "        self.entered_people_ids = set()  # IDs of people who have entered\n",
    "        self.movement_threshold = 8      # Minimum pixels to consider as movement\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.load_model(model_size)\n",
    "        \n",
    "    def load_model(self, model_size):\n",
    "        \"\"\"Load YOLO model with error handling\"\"\"\n",
    "        try:\n",
    "            from ultralytics import YOLO\n",
    "            \n",
    "            model_options = [f'yolo11{model_size}.pt', f'yolov8{model_size}.pt', 'yolo11n.pt', 'yolov8n.pt']\n",
    "            \n",
    "            for model_path in model_options:\n",
    "                try:\n",
    "                    print(f\"üì• Trying to load {model_path}...\")\n",
    "                    self.model = YOLO(model_path)\n",
    "                    self.model.conf = 0.5\n",
    "                    self.model.iou = 0.45\n",
    "                    self.model.max_det = 1000\n",
    "                    self.model_name = model_path\n",
    "                    print(f\"‚úÖ Successfully loaded {model_path}\")\n",
    "                    return\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            print(\"‚ùå All YOLO models failed to load\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"‚ùå Ultralytics not installed\")\n",
    "    \n",
    "    def detect_people_in_frame(self, frame):\n",
    "        \"\"\"Detect people and return bounding boxes\"\"\"\n",
    "        if self.model is None:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = self.model(frame, classes=[0], verbose=False)\n",
    "            people_boxes = []\n",
    "            \n",
    "            if results and len(results) > 0 and results[0].boxes is not None:\n",
    "                boxes = results[0].boxes\n",
    "                coords = boxes.xyxy.cpu().numpy()\n",
    "                confs = boxes.conf.cpu().numpy()\n",
    "                \n",
    "                for i in range(len(coords)):\n",
    "                    box = coords[i].astype(int)\n",
    "                    conf = float(confs[i])\n",
    "                    people_boxes.append([box[0], box[1], box[2], box[3]])\n",
    "            \n",
    "            return people_boxes\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Detection error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_movement_direction(self, objectID):\n",
    "        \"\"\"Calculate movement direction for tracked object\"\"\"\n",
    "        if objectID not in self.tracker.centroid_history:\n",
    "            return None, False\n",
    "        \n",
    "        history = self.tracker.centroid_history[objectID]\n",
    "        if len(history) < 4:  # Need enough points for reliable direction\n",
    "            return None, False\n",
    "        \n",
    "        # Get recent positions for direction calculation\n",
    "        recent_positions = history[-4:]\n",
    "        \n",
    "        # Calculate overall vertical movement\n",
    "        start_y = recent_positions[0][1]\n",
    "        end_y = recent_positions[-1][1]\n",
    "        vertical_movement = end_y - start_y\n",
    "        \n",
    "        # Check if movement is significant (not stationary)\n",
    "        if abs(vertical_movement) < self.movement_threshold:\n",
    "            return \"stationary\", False\n",
    "        \n",
    "        # Determine direction\n",
    "        if vertical_movement > 0:\n",
    "            return \"moving_down\", True  # Top to bottom (exiting)\n",
    "        else:\n",
    "            return \"moving_up\", True    # Bottom to top (entering)\n",
    "    \n",
    "    def filter_entering_people_only(self, objects, line_y):\n",
    "        \"\"\"Filter to show ONLY people who are entering (moving bottom‚Üítop)\"\"\"\n",
    "        entering_people = {}\n",
    "        new_entries_this_frame = []\n",
    "        \n",
    "        for objectID, centroid in objects.items():\n",
    "            current_y = centroid[1]\n",
    "            \n",
    "            # Get movement direction\n",
    "            direction, is_moving = self.get_movement_direction(objectID)\n",
    "            \n",
    "            # ONLY process people moving UP (entering)\n",
    "            if is_moving and direction == \"moving_up\":\n",
    "                \n",
    "                # Check if this person just crossed the line (entered)\n",
    "                if objectID in self.tracker.centroid_history and len(self.tracker.centroid_history[objectID]) >= 2:\n",
    "                    prev_y = self.tracker.centroid_history[objectID][-2][1]\n",
    "                    \n",
    "                    # Check for line crossing from bottom to top\n",
    "                    if prev_y > line_y and current_y <= line_y:\n",
    "                        if objectID not in self.entered_people_ids:\n",
    "                            self.total_entered_count += 1\n",
    "                            self.entered_people_ids.add(objectID)\n",
    "                            new_entries_this_frame.append({\n",
    "                                'objectID': objectID,\n",
    "                                'centroid': centroid,\n",
    "                                'just_entered': True\n",
    "                            })\n",
    "                            print(f\"‚úÖ Person {objectID} ENTERED! Total entered: {self.total_entered_count}\")\n",
    "                \n",
    "                # Add to display list (only entering people)\n",
    "                entering_people[objectID] = {\n",
    "                    'centroid': centroid,\n",
    "                    'direction': direction,\n",
    "                    'is_entered': objectID in self.entered_people_ids,\n",
    "                    'just_entered': any(entry['objectID'] == objectID for entry in new_entries_this_frame)\n",
    "                }\n",
    "            \n",
    "            # COMPLETELY IGNORE:\n",
    "            # - People moving down (exiting)\n",
    "            # - Stationary people\n",
    "            # - People not moving significantly\n",
    "        \n",
    "        return entering_people, new_entries_this_frame\n",
    "    \n",
    "    def calculate_display_size(self, video_width, video_height):\n",
    "        \"\"\"Calculate display size to fit screen\"\"\"\n",
    "        max_width = 1200\n",
    "        max_height = 800\n",
    "        \n",
    "        scale_width = max_width / video_width\n",
    "        scale_height = max_height / video_height\n",
    "        scale_factor = min(scale_width, scale_height, 1.0)\n",
    "        \n",
    "        display_width = int(video_width * scale_factor)\n",
    "        display_height = int(video_height * scale_factor)\n",
    "        \n",
    "        return display_width, display_height, scale_factor\n",
    "    \n",
    "    def draw_entering_people_only(self, frame, entering_people, new_entries, line_y, scale_factor=1.0):\n",
    "        \"\"\"Draw ONLY entering people and their tracking\"\"\"\n",
    "        annotated_frame = frame.copy()\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        font_scale = max(0.6, scale_factor * 0.8)\n",
    "        thickness = max(2, int(scale_factor * 3))\n",
    "        \n",
    "        # Draw the GREEN COUNTING LINE\n",
    "        cv2.line(annotated_frame, (0, line_y), (w, line_y), (0, 255, 0), thickness + 2)\n",
    "        cv2.putText(annotated_frame, 'ENTRY LINE (BOTTOM‚ÜíTOP ONLY)', (w // 2 - 200, line_y - 15),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.7, (0, 255, 0), thickness)\n",
    "        \n",
    "        # Draw ONLY entering people\n",
    "        for objectID, person_data in entering_people.items():\n",
    "            centroid = person_data['centroid']\n",
    "            is_entered = person_data['is_entered']\n",
    "            just_entered = person_data['just_entered']\n",
    "            \n",
    "            # Color coding for entering people only\n",
    "            if just_entered:\n",
    "                color = (0, 255, 255)  # Yellow for just entered\n",
    "                status = \"JUST ENTERED!\"\n",
    "                circle_radius = 15\n",
    "            elif is_entered:\n",
    "                color = (0, 255, 0)    # Green for previously entered\n",
    "                status = \"ENTERED\"\n",
    "                circle_radius = 10\n",
    "            else:\n",
    "                color = (0, 200, 255)  # Orange for approaching\n",
    "                status = \"APPROACHING\"\n",
    "                circle_radius = 8\n",
    "            \n",
    "            # Draw tracking circle\n",
    "            cv2.circle(annotated_frame, centroid, circle_radius, color, -1)\n",
    "            cv2.circle(annotated_frame, centroid, circle_radius + 3, color, 2)\n",
    "            \n",
    "            # Draw object ID and status\n",
    "            cv2.putText(annotated_frame, f\"ID:{objectID}\", \n",
    "                       (centroid[0] - 20, centroid[1] - 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.6, color, thickness)\n",
    "            cv2.putText(annotated_frame, status, \n",
    "                       (centroid[0] - 40, centroid[1] + 35),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.5, color, thickness)\n",
    "            \n",
    "            # Draw movement trail for entering people\n",
    "            if objectID in self.tracker.centroid_history:\n",
    "                history = self.tracker.centroid_history[objectID]\n",
    "                if len(history) > 1:\n",
    "                    for i in range(1, len(history)):\n",
    "                        cv2.line(annotated_frame, history[i-1], history[i], color, 3)\n",
    "        \n",
    "        # Highlight new entries with animation effect\n",
    "        for entry in new_entries:\n",
    "            centroid = entry['centroid']\n",
    "            cv2.circle(annotated_frame, centroid, 25, (0, 255, 255), 4)\n",
    "            cv2.putText(annotated_frame, \"NEW ENTRY!\", (centroid[0] - 50, centroid[1] - 40),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.8, (0, 255, 255), thickness + 1)\n",
    "        \n",
    "        # LEFT CORNER: Entry-only count display\n",
    "        overlay = annotated_frame.copy()\n",
    "        cv2.rectangle(overlay, (10, 10), (400, 160), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.8, annotated_frame, 0.2, 0, annotated_frame)\n",
    "        \n",
    "        # Count information - ONLY entries\n",
    "        cv2.putText(annotated_frame, 'ENTERING PEOPLE ONLY', (20, 35),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.9, (255, 255, 255), thickness)\n",
    "        \n",
    "        cv2.putText(annotated_frame, f'TOTAL ENTERED: {self.total_entered_count}', (20, 75),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 1.3, (0, 255, 0), thickness + 1)\n",
    "        \n",
    "        cv2.putText(annotated_frame, f'Currently Tracking: {len(entering_people)}', (20, 110),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.8, (0, 255, 255), thickness)\n",
    "        \n",
    "        # Legend - ONLY for entering people\n",
    "        cv2.putText(annotated_frame, 'Yellow=Just Entered, Green=Entered, Orange=Approaching', (20, 140),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, font_scale * 0.5, (200, 200, 200), thickness - 1)\n",
    "        \n",
    "        return annotated_frame\n",
    "    \n",
    "    def play_video_entering_only(self, video_path):\n",
    "        \"\"\"Play video showing ONLY entering people\"\"\"\n",
    "        \n",
    "        print(f\"üé• Opening video: {video_path}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"‚ùå Cannot open video: {video_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS)) or 25\n",
    "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps\n",
    "        \n",
    "        line_y = int(original_height * self.line_position_ratio)\n",
    "        display_width, display_height, scale_factor = self.calculate_display_size(\n",
    "            original_width, original_height\n",
    "        )\n",
    "        \n",
    "        print(f\"üìπ Video: {original_width}x{original_height}, {fps} FPS, {total_frames} frames\")\n",
    "        print(f\"üìè Entry line at Y = {line_y} ({self.line_position_ratio * 100:.1f}% from top)\")\n",
    "        print(f\"üéØ Mode: ENTERING PEOPLE ONLY (bottom‚Üítop)\")\n",
    "        print(f\"üö´ Ignoring: Exiting people (top‚Üíbottom) and stationary people\")\n",
    "        \n",
    "        cv2.namedWindow('Entering People Only Counter', cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Entering People Only Counter', display_width, display_height)\n",
    "        \n",
    "        frame_number = 0\n",
    "        start_time = time.time()\n",
    "        paused = False\n",
    "        \n",
    "        print(\"üé¨ Controls: 'q'=quit, SPACE=pause/resume, 'f'=fullscreen\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                if not paused:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"üìπ Video completed!\")\n",
    "                        break\n",
    "                    \n",
    "                    frame_number += 1\n",
    "                    self.frame_count += 1\n",
    "                    \n",
    "                    # Detect people\n",
    "                    people_boxes = self.detect_people_in_frame(frame)\n",
    "                    \n",
    "                    # Update tracker\n",
    "                    objects = self.tracker.update(people_boxes)\n",
    "                    \n",
    "                    # Filter to show ONLY entering people\n",
    "                    entering_people, new_entries = self.filter_entering_people_only(objects, line_y)\n",
    "                    \n",
    "                    # Print frame info - ONLY for entering people\n",
    "                    if entering_people or new_entries:\n",
    "                        print(f\"Frame {frame_number}: {len(entering_people)} entering people tracked | Total entered: {self.total_entered_count}\")\n",
    "                    \n",
    "                    # Draw ONLY entering people\n",
    "                    display_frame = self.draw_entering_people_only(\n",
    "                        frame, entering_people, new_entries, line_y, scale_factor\n",
    "                    )\n",
    "                    \n",
    "                    # Add progress info\n",
    "                    progress = (frame_number / total_frames) * 100\n",
    "                    timestamp = frame_number / fps\n",
    "                    cv2.putText(display_frame, f'Progress: {progress:.1f}% | Time: {timestamp:.1f}s', \n",
    "                               (original_width - int(300 * scale_factor), original_height - int(30 * scale_factor)),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, scale_factor * 0.6, (255, 255, 255), max(1, int(scale_factor * 2)))\n",
    "                    \n",
    "                    resized_frame = cv2.resize(display_frame, (display_width, display_height))\n",
    "                \n",
    "                cv2.imshow('Entering People Only Counter', resized_frame)\n",
    "                \n",
    "                key = cv2.waitKey(max(1, int(1000/fps))) & 0xFF\n",
    "                \n",
    "                if key == ord('q') or key == 27:\n",
    "                    print(\"üõë Stopped by user\")\n",
    "                    break\n",
    "                elif key == ord(' '):\n",
    "                    paused = not paused\n",
    "                    print(\"‚è∏Ô∏è Paused\" if paused else \"‚ñ∂Ô∏è Resumed\")\n",
    "                elif key == ord('f'):\n",
    "                    cv2.setWindowProperty('Entering People Only Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "                elif key == ord('n'):\n",
    "                    cv2.setWindowProperty('Entering People Only Counter', \n",
    "                                        cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüõë Interrupted by user\")\n",
    "        \n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\nüìä ENTERING-ONLY COUNTING COMPLETE:\")\n",
    "            print(f\"   üìè Entry line position: Y = {line_y} ({self.line_position_ratio * 100:.1f}% from top)\")\n",
    "            print(f\"   ‚úÖ TOTAL PEOPLE ENTERED: {self.total_entered_count}\")\n",
    "            print(f\"   üìπ Frames processed: {self.frame_count}\")\n",
    "            print(f\"   ‚è±Ô∏è Processing time: {processing_time:.1f}s\")\n",
    "            print(f\"   üéØ Mode: ENTERING ONLY (ignored exiting & stationary people)\")\n",
    "\n",
    "# Install required packages (run once)\n",
    "# pip install ultralytics opencv-python scipy\n",
    "\n",
    "# Initialize and use the entering-only counter\n",
    "print(\"üöÄ INITIALIZING ENTERING-ONLY PERSON COUNTER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Create entering-only counter\n",
    "    counter = EnteringOnlyPersonCounter('n', line_position_ratio=0.90)\n",
    "    \n",
    "    print(\"\\n‚úÖ INITIALIZATION SUCCESSFUL!\")\n",
    "    print(f\"üì± Model: {counter.model_name}\")\n",
    "    print(f\"üìè Entry line position: {counter.line_position_ratio * 100:.1f}% from top\")\n",
    "    \n",
    "    print(f\"\\nüéØ ENTERING-ONLY FEATURES:\")\n",
    "    print(f\"   ‚úÖ Only tracks people moving bottom‚Üítop (entering)\")\n",
    "    print(f\"   üö´ Completely ignores people moving top‚Üíbottom (exiting)\")\n",
    "    print(f\"   üö´ Completely ignores stationary people\")\n",
    "    print(f\"   üîç Only displays entering people with trails\")\n",
    "    print(f\"   üìä Shows only total entered count (no subtraction)\")\n",
    "    \n",
    "    print(f\"\\nüé¨ CONTROLS:\")\n",
    "    print(f\"   'q' or ESC = Quit\")\n",
    "    print(f\"   SPACE = Pause/Resume\")\n",
    "    print(f\"   'f' = Fullscreen\")\n",
    "    print(f\"   'n' = Normal window\")\n",
    "    \n",
    "    print(f\"\\nüé® VISUAL INDICATORS (ENTERING PEOPLE ONLY):\")\n",
    "    print(f\"   üü° Yellow circles = Just entered through line\")\n",
    "    print(f\"   üü¢ Green circles = Previously entered people\")\n",
    "    print(f\"   üü† Orange circles = Approaching entry line\")\n",
    "    print(f\"   üîç Colored trails = Movement paths of entering people\")\n",
    "    \n",
    "    # Run with your video\n",
    "    counter.play_video_entering_only('testing9.mp4')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüí° REQUIREMENTS:\")\n",
    "    print(\"   pip install ultralytics opencv-python scipy\")\n",
    "\n",
    "print(\"\\nüéâ ENTERING-ONLY COUNTING READY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f58c0f-1873-4291-9a66-c6aca5510df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
